{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "import json\n",
    "import re\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "from nltk_utils import tokenize\n",
    "from model import NeuralNet\n",
    "import nltk\n",
    "from gensim.models import Word2Vec, KeyedVectors\n",
    "from gensim.models.wrappers import FastText\n",
    "from selenium import webdriver\n",
    "from pprint import pprint\n",
    "import requests \n",
    "from bs4 import BeautifulSoup\n",
    "import unicodedata\n",
    "import pandas as pd\n",
    "import ast\n",
    "\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"Question & Answer.json\",encoding='utf-8', errors='ignore') as json_data:\n",
    "     chats = json.load(json_data, strict=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(chats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "EMBEDDING_FILE='glove.6B.100d.txt'\n",
    "def get_coefs(word,*arr): \n",
    "    return word, np.asarray(arr, dtype='float32')\n",
    "model__wv = dict(get_coefs(*o.strip().split()) for o in open(EMBEDDING_FILE, encoding=\"utf8\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "400000"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocabulary = model__wv.keys()\n",
    "len(vocabulary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = set(stopwords.words('english')) \n",
    "def processQues(chat):\n",
    "    chat = chat.lower()\n",
    "    chat = re.sub('((www\\.[^\\s]+)|(https?://[^\\s]+))','',chat)\n",
    "    chat = re.sub('@[^\\s]+','',chat)\n",
    "    chat = re.sub('[\\s]+', ' ', chat)\n",
    "    chat = re.sub(r'#([^\\s]+)', r'\\1', chat)\n",
    "    chat = re.sub(r'[\\.!:\\?\\-\\'\\\"\\\\/]', r'', chat)\n",
    "    chat = chat.strip('\\'\"')\n",
    "    return chat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_words = []\n",
    "tags = []\n",
    "xy = []\n",
    "# loop through each sentence in our intents patterns\n",
    "for con in chats:\n",
    "    tag = con['tags']\n",
    "    # add to tag list\n",
    "    tags.append(tag[0])\n",
    "    ques=con[\"question\"]\n",
    "    ques=processQues(ques)\n",
    "    # tokenize each word in the sentence\n",
    "    w = tokenize(ques)\n",
    "    w = [wd for wd in w if wd not in stop_words]\n",
    "    all_words.extend(w)\n",
    "    # add to xy pair\n",
    "    xy.append((w, tag[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove duplicates and sort\n",
    "all_words = sorted(set(all_words))\n",
    "tags = sorted(set(tags))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xy[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "pairs=[]\n",
    "for i in xy:\n",
    "    vec=i[0]\n",
    "    cls=i[1]\n",
    "    document = [word for word in vec if word in model__wv.keys()]\n",
    "    if (len(document)==0):\n",
    "        pass\n",
    "    else:\n",
    "        pairs.append((document,cls))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "136950"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(pairs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = []\n",
    "y_train = []\n",
    "for (pattern_sentence, tag) in pairs:\n",
    "    pat_list=[]\n",
    "    for i in pattern_sentence:\n",
    "        pat_list.append(model__wv[i])\n",
    "    vect=np.mean(pat_list, axis=0)\n",
    "    X_train.append(vect)\n",
    "    label = tags.index(tag)\n",
    "    y_train.append(label)\n",
    "\n",
    "X_train = np.array(X_train)\n",
    "y_train = np.array(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([-0.17040172,  0.55024934,  0.17760606, -0.07317873, -0.03597808,\n",
       "        -0.4012602 , -0.05297029,  0.1048191 ,  0.08812226, -0.07955843,\n",
       "         0.00394704, -0.26159886,  0.14613499,  0.38166744,  0.07533858,\n",
       "        -0.22742088,  0.2346472 , -0.00942885, -0.04003692, -0.02086451,\n",
       "        -0.21291885, -0.21882844, -0.27487144,  0.29213735,  0.13796379,\n",
       "         0.07480128,  0.10810026, -0.56742305, -0.15788008, -0.15723951,\n",
       "         0.18862203,  0.45313588, -0.28787237, -0.0961435 ,  0.21426557,\n",
       "         0.15385877, -0.04557906,  0.21416788,  0.01523628, -0.10103815,\n",
       "        -0.00154607, -0.12695557, -0.21169503, -0.52027225, -0.28858867,\n",
       "         0.00707572,  0.06867473,  0.04647522, -0.12436955, -0.5247038 ,\n",
       "        -0.1560386 ,  0.2905142 , -0.16276036,  0.40633008, -0.05235162,\n",
       "        -0.6100577 ,  0.20341988, -0.41187456,  0.7008843 ,  0.0484    ,\n",
       "        -0.044756  ,  0.46844307, -0.05985422,  0.40567446,  0.42498663,\n",
       "        -0.16379993,  0.3721475 ,  0.02224429,  0.10326406, -0.36891198,\n",
       "        -0.25944328,  0.19852415,  0.05600907,  0.16927373, -0.04991851,\n",
       "        -0.01340643,  0.21011165,  0.01991679, -0.2527592 , -0.28571728,\n",
       "         0.42996937, -0.0850039 ,  0.07241026,  0.0647615 , -0.99969727,\n",
       "         0.15948819,  0.22327968, -0.05958106, -0.43263617, -0.00481136,\n",
       "        -0.10918258, -0.01183308, -0.00159722,  0.01281541, -0.07730564,\n",
       "        -0.09093629, -0.16025016, -0.34757617,  0.5337135 ,  0.15745993],\n",
       "       dtype=float32),\n",
       " 10)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[0], y_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100, 13)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#np.save( 'trainX.npy' , X_train )\n",
    "#np.save( 'trainY.npy' , y_train )\n",
    "len(X_train[610]), len(tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100 13\n"
     ]
    }
   ],
   "source": [
    "# Hyper-parameters \n",
    "num_epochs = 50\n",
    "batch_size = 5000\n",
    "learning_rate = 0.0001\n",
    "input_size = len(X_train[0])\n",
    "hidden_size = 64\n",
    "output_size = len(tags)\n",
    "print(input_size, output_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['bariatrics',\n",
       " 'breast surgery',\n",
       " 'cardiac electrophysiology',\n",
       " 'cardiology',\n",
       " 'child psychiatry',\n",
       " 'clinical genetics',\n",
       " 'clinical lipidology',\n",
       " 'clinical psychology',\n",
       " 'colon and rectal surgery',\n",
       " 'critical care',\n",
       " 'dentistry',\n",
       " 'dermatology',\n",
       " 'wound care']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ChatDataset(Dataset):\n",
    "\n",
    "    def __init__(self):\n",
    "        self.n_samples = len(X_train)\n",
    "        self.x_data = X_train\n",
    "        self.y_data = y_train\n",
    "\n",
    "    # support indexing such that dataset[i] can be used to get i-th sample\n",
    "    def __getitem__(self, index):\n",
    "        return self.x_data[index], self.y_data[index]\n",
    "\n",
    "    # we can call len(dataset) to return the size\n",
    "    def __len__(self):\n",
    "        return self.n_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = ChatDataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(dataset=dataset,\n",
    "                          batch_size=batch_size,\n",
    "                          shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNet(nn.Module):\n",
    "    def __init__(self,input_size,output_size):\n",
    "        super(NeuralNet, self).__init__()\n",
    "        self.fc1=nn.Linear(input_size,128)\n",
    "        self.fc2=nn.Linear(128,64)\n",
    "        self.fc3=nn.Linear(64,32)\n",
    "        self.fc4=nn.Linear(32,output_size)\n",
    "        self.relu=nn.ReLU()\n",
    "        self.drop=nn.Dropout(p=0.4)\n",
    "        self.BatchNorm2=nn.BatchNorm1d(64)\n",
    "        self.BatchNorm3=nn.BatchNorm1d(32)\n",
    "        \n",
    "    def forward(self,X):\n",
    "        out=self.fc1(X)\n",
    "        out=self.relu(out)\n",
    "        out=self.drop(out)\n",
    "        \n",
    "        out=self.fc2(out)\n",
    "        out=self.relu(out)\n",
    "        out=self.BatchNorm2(out)\n",
    "        out=self.drop(out)\n",
    "        \n",
    "        out=self.fc3(out)\n",
    "        out=self.relu(out)\n",
    "        out=self.BatchNorm3(out)\n",
    "        out=self.drop(out)\n",
    "        \n",
    "        out=self.fc4(out)\n",
    "        \n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_4FC = NeuralNet(input_size, output_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loss and optimizer\n",
    "criterion = nn.CrossEntropyLoss()  # here softmax is inbuilt so no need to apply it in neural network\n",
    "optimizer = torch.optim.Adam(model_4FC.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/50], Loss: 2.5966\n",
      "49\n",
      "Epoch [2/50], Loss: 2.4619\n",
      "Epoch [3/50], Loss: 2.3262\n",
      "99\n",
      "Epoch [4/50], Loss: 2.1219\n",
      "Epoch [5/50], Loss: 2.0092\n",
      "149\n",
      "Epoch [6/50], Loss: 1.8724\n",
      "Epoch [7/50], Loss: 1.7571\n",
      "199\n",
      "Epoch [8/50], Loss: 1.6356\n",
      "249\n",
      "Epoch [9/50], Loss: 1.5884\n",
      "Epoch [10/50], Loss: 1.5086\n",
      "299\n",
      "Epoch [11/50], Loss: 1.4052\n",
      "Epoch [12/50], Loss: 1.4200\n",
      "349\n",
      "Epoch [13/50], Loss: 1.3778\n",
      "Epoch [14/50], Loss: 1.2524\n",
      "399\n",
      "Epoch [15/50], Loss: 1.2417\n",
      "Epoch [16/50], Loss: 1.1867\n",
      "449\n",
      "Epoch [17/50], Loss: 1.1821\n",
      "499\n",
      "Epoch [18/50], Loss: 1.1321\n",
      "Epoch [19/50], Loss: 1.1330\n",
      "549\n",
      "Epoch [20/50], Loss: 1.0911\n",
      "Epoch [21/50], Loss: 1.0334\n",
      "599\n",
      "Epoch [22/50], Loss: 1.0011\n",
      "Epoch [23/50], Loss: 0.9910\n",
      "649\n",
      "Epoch [24/50], Loss: 1.0083\n",
      "699\n",
      "Epoch [25/50], Loss: 0.9620\n",
      "Epoch [26/50], Loss: 0.9598\n",
      "749\n",
      "Epoch [27/50], Loss: 0.9195\n",
      "Epoch [28/50], Loss: 0.8937\n",
      "799\n",
      "Epoch [29/50], Loss: 0.8811\n",
      "Epoch [30/50], Loss: 0.8544\n",
      "849\n",
      "Epoch [31/50], Loss: 0.8672\n",
      "Epoch [32/50], Loss: 0.8397\n",
      "899\n",
      "Epoch [33/50], Loss: 0.8478\n",
      "949\n",
      "Epoch [34/50], Loss: 0.8429\n",
      "Epoch [35/50], Loss: 0.8256\n",
      "999\n",
      "Epoch [36/50], Loss: 0.8189\n",
      "Epoch [37/50], Loss: 0.7519\n",
      "1049\n",
      "Epoch [38/50], Loss: 0.7917\n",
      "Epoch [39/50], Loss: 0.7936\n",
      "1099\n",
      "Epoch [40/50], Loss: 0.7859\n",
      "Epoch [41/50], Loss: 0.7506\n",
      "1149\n",
      "Epoch [42/50], Loss: 0.7643\n",
      "1199\n",
      "Epoch [43/50], Loss: 0.7464\n",
      "Epoch [44/50], Loss: 0.7189\n",
      "1249\n",
      "Epoch [45/50], Loss: 0.7185\n",
      "Epoch [46/50], Loss: 0.7172\n",
      "1299\n",
      "Epoch [47/50], Loss: 0.7023\n",
      "Epoch [48/50], Loss: 0.6513\n",
      "1349\n",
      "Epoch [49/50], Loss: 0.6717\n",
      "1399\n",
      "Epoch [50/50], Loss: 0.6858\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "count=0\n",
    "for epoch in range(num_epochs):\n",
    "    for (words, labels) in train_loader:\n",
    "        #words = words\n",
    "        labels = labels.long()\n",
    "        \n",
    "        # Forward pass\n",
    "        outputs = model_4FC(words)\n",
    "        loss = criterion(outputs, labels)\n",
    "        \n",
    "        # Backward and optimize\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        count+=1\n",
    "        if (count+1) % 50 ==0:\n",
    "            print(count)\n",
    "        \n",
    "    if (epoch+1) % 1 == 0:\n",
    "        print (f'Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method Module.parameters of NeuralNet(\n",
       "  (fc1): Linear(in_features=100, out_features=128, bias=True)\n",
       "  (fc2): Linear(in_features=128, out_features=64, bias=True)\n",
       "  (fc3): Linear(in_features=64, out_features=32, bias=True)\n",
       "  (fc4): Linear(in_features=32, out_features=13, bias=True)\n",
       "  (relu): ReLU()\n",
       "  (drop): Dropout(p=0.4, inplace=False)\n",
       "  (BatchNorm2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (BatchNorm3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       ")>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_4FC.parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {\n",
    "\"model_state\": model_3FC.state_dict(),\n",
    "\"input_size\": input_size,\n",
    "\"output_size\": output_size,\n",
    "\"all_words\": all_words,\n",
    "\"tags\": tags\n",
    "}\n",
    "\n",
    "FILE = \"doc_data.pth\"\n",
    "torch.save(data, FILE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training complete. file saved to doc_data.pth\n"
     ]
    }
   ],
   "source": [
    "print(f'training complete. file saved to {FILE}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'question': 'zirconium dental implants. how common is it used now. is there any advantages or benefits over titanium implants. cons & pros please. thanks.',\n",
       " 'short_answer': '\\nDental implants\\n',\n",
       " 'answer': 'a majority of the dental implants placed are titanium. they are highly successful with many years use ; many studies much lower in cost ; have many restorative options. zirconia implants are newer fewer studies on success lesser restorative options. however they can be more aesthetic in certain anterior(front) situations. let your dentist/oral surgeon chose what they feel will be best for you.',\n",
       " 'tags': ['dentistry'],\n",
       " 'url': 'https://www.healthtap.com/user_questions/1160508-zirconium-dental-implants-how-common-is-it-used-now-is-there-any-advantages-or-benefits-over-titan'}"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chats[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#FILE = \"doc_data.pth\"\n",
    "#data = torch.load(FILE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'input_size = data[\"input_size\"]\\noutput_size = data[\"output_size\"]\\nall_words = data[\\'all_words\\']\\ntags = data[\\'tags\\']\\nmodel_state = data[\"model_state\"]'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''input_size = data[\"input_size\"]\n",
    "output_size = data[\"output_size\"]\n",
    "all_words = data['all_words']\n",
    "tags = data['tags']\n",
    "model_state = data[\"model_state\"]'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NeuralNet(\n",
       "  (fc1): Linear(in_features=100, out_features=128, bias=True)\n",
       "  (fc2): Linear(in_features=128, out_features=64, bias=True)\n",
       "  (fc3): Linear(in_features=64, out_features=32, bias=True)\n",
       "  (fc4): Linear(in_features=32, out_features=13, bias=True)\n",
       "  (relu): ReLU()\n",
       "  (drop): Dropout(p=0.4, inplace=False)\n",
       "  (BatchNorm2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (BatchNorm3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       ")"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#model = NeuralNet(input_size, output_size)\n",
    "#model.load_state_dict(model_state)\n",
    "model_4FC.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "intent_dict={}\n",
    "for intent in tags:\n",
    "    int_list=[]\n",
    "    for chat in chats:\n",
    "        if(chat[\"tags\"][0]==intent):\n",
    "            int_list.append(chat[\"short_answer\"])\n",
    "    intent_dict[intent]=int_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bot_name = \"Robo: \"\n",
    "print(\"----------------Your Personal Doctor! (type 'bye' to exit)-------------------\")\n",
    "while True:\n",
    "    sentence = input(\"You: \")\n",
    "    if sentence == \"bye\":\n",
    "        break\n",
    "    sentence=processQues(sentence)\n",
    "    sentence = tokenize(sentence)\n",
    "    sentence = [wd for wd in sentence if wd not in stop_words]\n",
    "    #print(sentence)\n",
    "    pat_list=[]\n",
    "    for i in sentence:\n",
    "        pat_list.append(model__wv[i])\n",
    "    vect=np.mean(pat_list, axis=0)\n",
    "    X = vect.reshape(1, vect.shape[0])\n",
    "    X = torch.from_numpy(X)\n",
    "\n",
    "    output = model_4FC(X)\n",
    "    _, predicted = torch.max(output, dim=1)\n",
    "\n",
    "    tag = tags[predicted.item()]\n",
    "    #print(tag)\n",
    "    probs = torch.softmax(output, dim=1)\n",
    "    prob = probs[0][predicted.item()]\n",
    "    print(prob.item())\n",
    "    if prob.item() > 0.40:\n",
    "        print(f\"{bot_name}: {random.choice(intent_dict[tag])}\")\n",
    "    else:\n",
    "        print(f\"{bot_name}: I do not understand...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7 GPU",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
