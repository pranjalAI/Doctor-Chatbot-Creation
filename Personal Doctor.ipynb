{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import pickle\n",
    "from tensorflow.keras import layers , activations , models , preprocessing\n",
    "from tensorflow.keras import preprocessing , utils\n",
    "import os\n",
    "import yaml\n",
    "import json\n",
    "import pandas as pd\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"Question & Answer.json\",encoding='utf-8', errors='ignore') as json_data:\n",
    "     chats = json.load(json_data, strict=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "137052"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(chats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'question': 'zirconium dental implants. how common is it used now. is there any advantages or benefits over titanium implants. cons & pros please. thanks.',\n",
       "  'short_answer': '\\nDental implants\\n',\n",
       "  'answer': 'a majority of the dental implants placed are titanium. they are highly successful with many years use ; many studies much lower in cost ; have many restorative options. zirconia implants are newer fewer studies on success lesser restorative options. however they can be more aesthetic in certain anterior(front) situations. let your dentist/oral surgeon chose what they feel will be best for you.',\n",
       "  'tags': ['dentistry'],\n",
       "  'url': 'https://www.healthtap.com/user_questions/1160508-zirconium-dental-implants-how-common-is-it-used-now-is-there-any-advantages-or-benefits-over-titan'}]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chats[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "questions_for_token = list()\n",
    "answers_for_token = list()\n",
    "\n",
    "for con in chats:\n",
    "    questions_for_token.append(con['question'])\n",
    "    answers_for_token.append(con['answer'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_QA = list()\n",
    "questions = list()\n",
    "answers = list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "count=0\n",
    "for con in chats:\n",
    "    questions.append(con['question'])\n",
    "    answers.append(con['answer'])\n",
    "    count+=1\n",
    "    if(count>=100):\n",
    "        final_QA.append([questions,answers])\n",
    "        count=0\n",
    "        questions = list()\n",
    "        answers = list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "del(chats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1370"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(final_QA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(final_QA[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(final_QA[0][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "embed_size = 100 # how big is each word vector\n",
    "max_features=60000\n",
    "maxlen=100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "def processTweet(chat):\n",
    "    chat = chat.lower()\n",
    "    chat = re.sub('((www\\.[^\\s]+)|(https?://[^\\s]+))','',chat)\n",
    "    chat = re.sub('@[^\\s]+','',chat)\n",
    "    chat = re.sub('[\\s]+', ' ', chat)\n",
    "    chat = re.sub(r'#([^\\s]+)', r'\\1', chat)\n",
    "    chat = re.sub(r'[\\.!:\\?\\-\\'\\\"\\\\/]', r'', chat)\n",
    "    chat = chat.strip('\\'\"')\n",
    "    return chat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getStopWordList(stopWordListFileName):\n",
    "    #read the stopwords file and build a list\n",
    "    stopWords = []\n",
    "    fp = open(stopWordListFileName, 'r')\n",
    "    line = fp.readline()\n",
    "    while line:\n",
    "        word = line.strip()\n",
    "        stopWords.append(word)\n",
    "        line = fp.readline()\n",
    "    fp.close()\n",
    "    return stopWords\n",
    "#stopWords = getStopWordList('StopWords.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def replaceTwoOrMore(s):\n",
    "    #look for 2 or more repetitions of character and replace with the character itself\n",
    "    pattern = re.compile(r\"(.)\\1{2,}\", re.DOTALL)\n",
    "    return pattern.sub(r\"\\1\", s)\n",
    "def getFeatureVector(chat):\n",
    "    chat=processTweet(chat)\n",
    "    featureVector = []\n",
    "    #split tweet into words\n",
    "    words = chat.split()\n",
    "    for w in words:\n",
    "        #replace two or more with two occurrences\n",
    "        w = replaceTwoOrMore(w)\n",
    "        #strip punctuation\n",
    "        w = w.strip('\\'\"?,.')\n",
    "        #check if the word stats with an alphabet\n",
    "        val = re.search(r\"^[a-zA-Z][a-zA-Z0-9]*$\", w)\n",
    "        #ignore if it is a stop word\n",
    "        if(val is None):\n",
    "            continue\n",
    "        else:\n",
    "            featureVector.append(w.lower())\n",
    "    return \" \".join(list(featureVector))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stringCropper(string):\n",
    "    if(\".\" in string):\n",
    "        split_string=string.strip().split(\".\")\n",
    "        if(len(split_string)>1 ):\n",
    "            split_string=\".\".join(split_string[:2])\n",
    "            return split_string\n",
    "        else:\n",
    "            return \".\".join(split_string)\n",
    "    else:\n",
    "        return string\n",
    "\n",
    "def stringCropperQues(string):\n",
    "    if(\".\" in string):\n",
    "        split_string=string.strip().split(\".\")\n",
    "        if(len(split_string)>0 ):\n",
    "            split_string=\".\".join(split_string[:1])\n",
    "            return split_string\n",
    "        else:\n",
    "            return \".\".join(split_string)\n",
    "    else:\n",
    "        return string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def emb_mat(nb_words):\n",
    "    EMBEDDING_FILE=\"glove.6B.100d.txt\"\n",
    "    def get_coefs(word,*arr): \n",
    "        return word, np.asarray(arr, dtype='float32')\n",
    "    embeddings_index = dict(get_coefs(*o.strip().split()) for o in open(EMBEDDING_FILE, encoding=\"utf8\"))\n",
    "\n",
    "    all_embs = np.stack(embeddings_index.values())\n",
    "    emb_mean,emb_std = all_embs.mean(), all_embs.std()\n",
    "    emb_mean,emb_std\n",
    "\n",
    "    embedding_matrix = np.random.normal(emb_mean, emb_std, (nb_words+1, embed_size))\n",
    "    for word, i in word_index.items():\n",
    "        if (i >= max_features) or i==nb_words:\n",
    "            continue\n",
    "        embedding_vector = embeddings_index.get(word) #here we will get embedding for each word from GloVe\n",
    "        if embedding_vector is not None:\n",
    "            embedding_matrix[i] = embedding_vector\n",
    "            \n",
    "    return embedding_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenized_data(questions,answers,VOCAB_SIZE,tokenizer):\n",
    "    # encoder_input_data\n",
    "    import numpy as np\n",
    "    tokenized_questions = tokenizer.texts_to_sequences( questions )\n",
    "    maxlen_questions = max( [ len(x) for x in tokenized_questions ] )\n",
    "    padded_questions = preprocessing.sequence.pad_sequences( tokenized_questions , maxlen=maxlen , padding='post' )\n",
    "    encoder_input_data = np.array( padded_questions )\n",
    "    #print( encoder_input_data.shape , maxlen_questions )\n",
    "\n",
    "    # decoder_input_data\n",
    "    tokenized_answers = tokenizer.texts_to_sequences( answers )\n",
    "    maxlen_answers = max( [ len(x) for x in tokenized_answers ] )\n",
    "    padded_answers = preprocessing.sequence.pad_sequences( tokenized_answers , maxlen=maxlen , padding='post' )\n",
    "    decoder_input_data = np.array( padded_answers )\n",
    "    #print( decoder_input_data.shape , maxlen_answers )\n",
    "\n",
    "    # decoder_output_data\n",
    "    tokenized_answers = tokenizer.texts_to_sequences( answers )\n",
    "    for i in range(len(tokenized_answers)) :\n",
    "        tokenized_answers[i] = tokenized_answers[i][1:] # remove <start> take rest\n",
    "    padded_answers = preprocessing.sequence.pad_sequences( tokenized_answers , maxlen=maxlen , padding='post' )\n",
    "    onehot_answers = utils.to_categorical( padded_answers , VOCAB_SIZE)\n",
    "    decoder_output_data = np.array( onehot_answers )\n",
    "    #print( decoder_output_data.shape )\n",
    "    \n",
    "    return [encoder_input_data,decoder_input_data,decoder_output_data,maxlen_questions,maxlen_answers]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pranj\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3331: FutureWarning: arrays to stack must be passed as a \"sequence\" type such as list or tuple. Support for non-sequence iterables such as generators is deprecated as of NumPy 1.16 and will raise an error in the future.\n",
      "  exec(code_obj, self.user_global_ns, self.user_ns)\n"
     ]
    }
   ],
   "source": [
    "answers_for_token=pd.DataFrame(answers_for_token, columns=[\"Ans\"])\n",
    "questions_for_token=pd.DataFrame(questions_for_token, columns=[\"Question\"])\n",
    "answers_for_token[\"cleanedAns\"]=answers_for_token[\"Ans\"].apply(stringCropper)\n",
    "questions_for_token[\"cleanedQues\"]=questions_for_token[\"Question\"].apply(stringCropperQues)\n",
    "answers_for_token[\"TokAns\"]=answers_for_token[\"cleanedAns\"].apply(getFeatureVector)\n",
    "questions_for_token[\"TokQues\"]=questions_for_token[\"cleanedQues\"].apply(getFeatureVector)\n",
    "\n",
    "answers_for_token=np.array(answers_for_token[\"TokAns\"])\n",
    "questions_for_token=np.array(questions_for_token[\"TokQues\"])\n",
    "\n",
    "answers_with_tags = list()\n",
    "for i in range( len( answers_for_token ) ):\n",
    "    if type( answers_for_token[i] ) == str:\n",
    "        answers_with_tags.append( answers_for_token[i] )\n",
    "    else:\n",
    "        print(questions_for_token[i])\n",
    "        print(answers_for_token[i])\n",
    "        print(type(answers_for_token[i]))\n",
    "        questions_for_token.pop(i)\n",
    "\n",
    "answers_for_token = list()\n",
    "for i in range( len( answers_with_tags ) ) :\n",
    "    answers_for_token.append( '<START> ' + answers_with_tags[i] + ' <END>' )\n",
    "\n",
    "tokenizer = preprocessing.text.Tokenizer()\n",
    "tokenizer.fit_on_texts(questions_for_token+answers_for_token)\n",
    "\n",
    "word_index = tokenizer.word_index\n",
    "nb_words = min(max_features, len(word_index))\n",
    "\n",
    "embedding_matrix=emb_mat(nb_words)\n",
    "\n",
    "VOCAB_SIZE = len( tokenizer.word_index )+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(58069, 58068)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "VOCAB_SIZE, nb_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def enable_gpu():\n",
    "    config = tf.compat.v1.ConfigProto( device_count = {'GPU': 1 , 'CPU': 56} ) \n",
    "    sess = tf.compat.v1.Session(config=config) \n",
    "    #keras.backend.set_session(sess)\n",
    "    tf.compat.v1.keras.backend.set_session(\n",
    "        sess\n",
    "    )\n",
    "    gpu_options = tf.compat.v1.GPUOptions(allow_growth=True, per_process_gpu_memory_fraction=0.333)\n",
    "    session = tf.compat.v1.InteractiveSession(config=tf.compat.v1.ConfigProto(gpu_options=gpu_options))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model(nb_words,embed_size,embedding_matrix):\n",
    "    #Defining model architecture for seq2seq Model\n",
    "    # return_seq=T -> gives hidden state o/p at each time step\n",
    "    #return_state =T -> Gives hidden state and cell o/p of only last time step\n",
    "    #if both options not given -> hidden state of last time step\n",
    "    encoder_inputs = tf.keras.layers.Input(shape=( None , ))\n",
    "    encoder_embedding = tf.keras.layers.Embedding( nb_words+1, embed_size , mask_zero=True ,weights=[embedding_matrix]) (encoder_inputs)\n",
    "    encoder_outputs , state_h , state_c = tf.keras.layers.LSTM( 200 , return_state=True )( encoder_embedding )\n",
    "    encoder_states = [ state_h , state_c ]\n",
    "\n",
    "    decoder_inputs = tf.keras.layers.Input(shape=( None ,  ))\n",
    "    decoder_embedding = tf.keras.layers.Embedding( nb_words+1, embed_size , mask_zero=True,weights=[embedding_matrix]) (decoder_inputs)\n",
    "    decoder_lstm = tf.keras.layers.LSTM( 200 , return_state=True , return_sequences=True )\n",
    "    decoder_outputs , _ , _ = decoder_lstm ( decoder_embedding , initial_state=encoder_states )\n",
    "\n",
    "    decoder_dense = tf.keras.layers.Dense( nb_words+1 , activation=tf.keras.activations.softmax ) \n",
    "    output = decoder_dense ( decoder_outputs )\n",
    "\n",
    "    model = tf.keras.models.Model([encoder_inputs, decoder_inputs], output )\n",
    "    return model,encoder_inputs,encoder_states,decoder_lstm,decoder_embedding,decoder_dense,decoder_inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the checkpoint\n",
    "filepath = \"model_DoctorChat.h5\"\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='loss', verbose=1, save_best_only=True, mode='min')\n",
    "callbacks_list = [checkpoint]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_data(questions,answers):\n",
    "    answers=pd.DataFrame(answers, columns=[\"Ans\"])\n",
    "    questions=pd.DataFrame(questions, columns=[\"Question\"])\n",
    "\n",
    "    answers[\"cleanedAns\"]=answers[\"Ans\"].apply(stringCropper)\n",
    "    questions[\"cleanedQues\"]=questions[\"Question\"].apply(stringCropperQues)\n",
    "    answers[\"TokAns\"]=answers[\"cleanedAns\"].apply(getFeatureVector)\n",
    "    questions[\"TokQues\"]=questions[\"cleanedQues\"].apply(getFeatureVector)\n",
    "\n",
    "    answers=np.array(answers[\"TokAns\"])\n",
    "    questions=np.array(questions[\"TokQues\"])\n",
    "\n",
    "    answers_with_tags = list()\n",
    "    for i in range( len( answers ) ):\n",
    "        if type( answers[i] ) == str:\n",
    "            answers_with_tags.append( answers[i] )\n",
    "        else:\n",
    "            print(questions[i])\n",
    "            print(answers[i])\n",
    "            print(type(answers[i]))\n",
    "            questions.pop(i)\n",
    "\n",
    "    answers = list()\n",
    "    for i in range( len( answers_with_tags ) ) :\n",
    "        answers.append( '<START> ' + answers_with_tags[i] + ' <END>' )\n",
    "\n",
    "    tok_out=tokenized_data(questions,answers,VOCAB_SIZE,tokenizer)\n",
    "    encoder_input_data=tok_out[0]\n",
    "    decoder_input_data=tok_out[1]\n",
    "    decoder_output_data=tok_out[2]\n",
    "    maxlen_questions=tok_out[3]\n",
    "    maxlen_answers=tok_out[4]\n",
    "    \n",
    "    return [encoder_input_data,decoder_input_data,decoder_output_data,maxlen_questions,maxlen_answers]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "enable_gpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "Prepared_data=prepare_data(final_QA[0][0],final_QA[0][1])\n",
    "print(\"Preparation done\")\n",
    "encoder_input_data=Prepared_data[0]\n",
    "print(\"Encoder done\")\n",
    "decoder_input_data=Prepared_data[1]\n",
    "decoder_output_data=Prepared_data[2]\n",
    "print(\"Decoder done\")\n",
    "maxlen_questions=Prepared_data[3]\n",
    "maxlen_answers=Prepared_data[4]\n",
    "print(encoder_input_data.shape, decoder_input_data.shape, decoder_output_data.shape)\n",
    "#model,encoder_inputs,encoder_states,decoder_lstm,decoder_embedding,decoder_dense,decoder_inputs\n",
    "get_model_out=get_model(nb_words,embed_size,embedding_matrix)\n",
    "model=get_model_out[0]\n",
    "encoder_inputs=get_model_out[1]\n",
    "encoder_states=get_model_out[2]\n",
    "decoder_lstm=get_model_out[3]\n",
    "decoder_embedding=get_model_out[4]\n",
    "decoder_dense=get_model_out[5]\n",
    "decoder_inputs=get_model_out[6]\n",
    "model.compile(optimizer=tf.keras.optimizers.RMSprop(), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "model.fit([encoder_input_data , decoder_input_data], decoder_output_data, batch_size=5, epochs=10, callbacks=callbacks_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_model_out=get_model(nb_words,embed_size,embedding_matrix)\n",
    "model=get_model_out[0]\n",
    "encoder_inputs=get_model_out[1]\n",
    "encoder_states=get_model_out[2]\n",
    "decoder_lstm=get_model_out[3]\n",
    "decoder_embedding=get_model_out[4]\n",
    "decoder_dense=get_model_out[5]\n",
    "decoder_inputs=get_model_out[6]\n",
    "model.compile(optimizer=tf.keras.optimizers.RMSprop(), loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#del(decoder_output_data)\n",
    "#del(decoder_input_data)\n",
    "#del(encoder_input_data)\n",
    "#del(chats)\n",
    "#del(answers)\n",
    "#del(questions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving all the arrays to storage\n",
    "#np.save( 'enc_in_data_PD.npy' , encoder_input_data )\n",
    "#np.save( 'dec_in_data_PD.npy' , decoder_input_data )\n",
    "#np.save( 'dec_tar_data_PD.npy' , decoder_output_data )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#encoder_input_data=np.load(\"enc_in_data_PD.npy\")\n",
    "#decoder_input_data=np.load(\"dec_in_data_PD.npy\")\n",
    "#decoder_output_data=np.load(\"dec_tar_data_PD.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 100 samples\n",
      "Epoch 1/20\n",
      " 95/100 [===========================>..] - ETA: 0s - loss: 1.9709 - accuracy: 0.1467\n",
      "Epoch 00001: loss improved from inf to 1.95073, saving model to model_DoctorChat.h5\n",
      "100/100 [==============================] - 12s 120ms/sample - loss: 1.9507 - accuracy: 0.1465\n",
      "Epoch 2/20\n",
      " 95/100 [===========================>..] - ETA: 0s - loss: 1.7101 - accuracy: 0.2042\n",
      "Epoch 00002: loss improved from 1.95073 to 1.71691, saving model to model_DoctorChat.h5\n",
      "100/100 [==============================] - 10s 96ms/sample - loss: 1.7169 - accuracy: 0.2050\n",
      "Epoch 3/20\n",
      " 95/100 [===========================>..] - ETA: 0s - loss: 1.5701 - accuracy: 0.2464\n",
      "Epoch 00003: loss improved from 1.71691 to 1.55856, saving model to model_DoctorChat.h5\n",
      "100/100 [==============================] - 9s 94ms/sample - loss: 1.5586 - accuracy: 0.2463\n",
      "Epoch 4/20\n",
      " 95/100 [===========================>..] - ETA: 0s - loss: 1.4560 - accuracy: 0.2819\n",
      "Epoch 00004: loss improved from 1.55856 to 1.43339, saving model to model_DoctorChat.h5\n",
      "100/100 [==============================] - 9s 94ms/sample - loss: 1.4334 - accuracy: 0.2890\n",
      "Epoch 5/20\n",
      " 95/100 [===========================>..] - ETA: 0s - loss: 1.3310 - accuracy: 0.3312\n",
      "Epoch 00005: loss improved from 1.43339 to 1.32450, saving model to model_DoctorChat.h5\n",
      "100/100 [==============================] - 9s 95ms/sample - loss: 1.3245 - accuracy: 0.3350\n",
      "Epoch 6/20\n",
      " 95/100 [===========================>..] - ETA: 0s - loss: 1.2385 - accuracy: 0.3653\n",
      "Epoch 00006: loss improved from 1.32450 to 1.22924, saving model to model_DoctorChat.h5\n",
      "100/100 [==============================] - 9s 93ms/sample - loss: 1.2292 - accuracy: 0.3670\n",
      "Epoch 7/20\n",
      " 95/100 [===========================>..] - ETA: 0s - loss: 1.1307 - accuracy: 0.4172\n",
      "Epoch 00007: loss improved from 1.22924 to 1.13600, saving model to model_DoctorChat.h5\n",
      "100/100 [==============================] - 9s 94ms/sample - loss: 1.1360 - accuracy: 0.4215\n",
      "Epoch 8/20\n",
      " 95/100 [===========================>..] - ETA: 0s - loss: 1.0463 - accuracy: 0.4668\n",
      "Epoch 00008: loss improved from 1.13600 to 1.05661, saving model to model_DoctorChat.h5\n",
      "100/100 [==============================] - 9s 94ms/sample - loss: 1.0566 - accuracy: 0.4654\n",
      "Epoch 9/20\n",
      " 95/100 [===========================>..] - ETA: 0s - loss: 0.9849 - accuracy: 0.4944\n",
      "Epoch 00009: loss improved from 1.05661 to 0.97927, saving model to model_DoctorChat.h5\n",
      "100/100 [==============================] - 11s 105ms/sample - loss: 0.9793 - accuracy: 0.4952\n",
      "Epoch 10/20\n",
      " 95/100 [===========================>..] - ETA: 0s - loss: 0.9042 - accuracy: 0.5247\n",
      "Epoch 00010: loss improved from 0.97927 to 0.91010, saving model to model_DoctorChat.h5\n",
      "100/100 [==============================] - 10s 97ms/sample - loss: 0.9101 - accuracy: 0.5235\n",
      "Epoch 11/20\n",
      " 95/100 [===========================>..] - ETA: 0s - loss: 0.8415 - accuracy: 0.5689\n",
      "Epoch 00011: loss improved from 0.91010 to 0.84017, saving model to model_DoctorChat.h5\n",
      "100/100 [==============================] - 9s 94ms/sample - loss: 0.8402 - accuracy: 0.5652\n",
      "Epoch 12/20\n",
      " 95/100 [===========================>..] - ETA: 0s - loss: 0.7672 - accuracy: 0.6149\n",
      "Epoch 00012: loss improved from 0.84017 to 0.77594, saving model to model_DoctorChat.h5\n",
      "100/100 [==============================] - 9s 94ms/sample - loss: 0.7759 - accuracy: 0.6115\n",
      "Epoch 13/20\n",
      " 95/100 [===========================>..] - ETA: 0s - loss: 0.7164 - accuracy: 0.6419\n",
      "Epoch 00013: loss improved from 0.77594 to 0.71533, saving model to model_DoctorChat.h5\n",
      "100/100 [==============================] - 9s 95ms/sample - loss: 0.7153 - accuracy: 0.6409\n",
      "Epoch 14/20\n",
      " 95/100 [===========================>..] - ETA: 0s - loss: 0.6665 - accuracy: 0.6739\n",
      "Epoch 00014: loss improved from 0.71533 to 0.65746, saving model to model_DoctorChat.h5\n",
      "100/100 [==============================] - 9s 95ms/sample - loss: 0.6575 - accuracy: 0.6732\n",
      "Epoch 15/20\n",
      " 95/100 [===========================>..] - ETA: 0s - loss: 0.6005 - accuracy: 0.7113\n",
      "Epoch 00015: loss improved from 0.65746 to 0.60220, saving model to model_DoctorChat.h5\n",
      "100/100 [==============================] - 9s 93ms/sample - loss: 0.6022 - accuracy: 0.7084\n",
      "Epoch 16/20\n",
      " 95/100 [===========================>..] - ETA: 0s - loss: 0.5574 - accuracy: 0.7380\n",
      "Epoch 00016: loss improved from 0.60220 to 0.54855, saving model to model_DoctorChat.h5\n",
      "100/100 [==============================] - 9s 95ms/sample - loss: 0.5485 - accuracy: 0.7397\n",
      "Epoch 17/20\n",
      " 95/100 [===========================>..] - ETA: 0s - loss: 0.4839 - accuracy: 0.7656\n",
      "Epoch 00017: loss improved from 0.54855 to 0.49784, saving model to model_DoctorChat.h5\n",
      "100/100 [==============================] - 9s 94ms/sample - loss: 0.4978 - accuracy: 0.7630\n",
      "Epoch 18/20\n",
      " 95/100 [===========================>..] - ETA: 0s - loss: 0.4431 - accuracy: 0.7891\n",
      "Epoch 00018: loss improved from 0.49784 to 0.45079, saving model to model_DoctorChat.h5\n",
      "100/100 [==============================] - 9s 93ms/sample - loss: 0.4508 - accuracy: 0.7856\n",
      "Epoch 19/20\n",
      " 95/100 [===========================>..] - ETA: 0s - loss: 0.4131 - accuracy: 0.8023\n",
      "Epoch 00019: loss improved from 0.45079 to 0.40698, saving model to model_DoctorChat.h5\n",
      "100/100 [==============================] - 9s 93ms/sample - loss: 0.4070 - accuracy: 0.8007\n",
      "Epoch 20/20\n",
      " 95/100 [===========================>..] - ETA: 0s - loss: 0.3637 - accuracy: 0.8258\n",
      "Epoch 00020: loss improved from 0.40698 to 0.36446, saving model to model_DoctorChat.h5\n",
      "100/100 [==============================] - 9s 92ms/sample - loss: 0.3645 - accuracy: 0.8244\n",
      "110/100 Sets Completed.\n",
      "Train on 100 samples\n",
      "Epoch 1/20\n",
      " 95/100 [===========================>..] - ETA: 0s - loss: 2.1456 - accuracy: 0.1633\n",
      "Epoch 00001: loss improved from inf to 2.14229, saving model to model_DoctorChat.h5\n",
      "100/100 [==============================] - 12s 122ms/sample - loss: 2.1423 - accuracy: 0.1628\n",
      "Epoch 2/20\n",
      " 95/100 [===========================>..] - ETA: 0s - loss: 1.8865 - accuracy: 0.2094\n",
      "Epoch 00002: loss improved from 2.14229 to 1.87175, saving model to model_DoctorChat.h5\n",
      "100/100 [==============================] - 9s 92ms/sample - loss: 1.8718 - accuracy: 0.2172\n",
      "Epoch 3/20\n",
      " 95/100 [===========================>..] - ETA: 0s - loss: 1.7056 - accuracy: 0.2650\n",
      "Epoch 00003: loss improved from 1.87175 to 1.68812, saving model to model_DoctorChat.h5\n",
      "100/100 [==============================] - 9s 95ms/sample - loss: 1.6881 - accuracy: 0.2611\n",
      "Epoch 4/20\n",
      " 95/100 [===========================>..] - ETA: 0s - loss: 1.5550 - accuracy: 0.3057\n",
      "Epoch 00004: loss improved from 1.68812 to 1.54601, saving model to model_DoctorChat.h5\n",
      "100/100 [==============================] - 9s 93ms/sample - loss: 1.5460 - accuracy: 0.3037\n",
      "Epoch 5/20\n",
      " 95/100 [===========================>..] - ETA: 0s - loss: 1.4126 - accuracy: 0.3480\n",
      "Epoch 00005: loss improved from 1.54601 to 1.42650, saving model to model_DoctorChat.h5\n",
      "100/100 [==============================] - 9s 94ms/sample - loss: 1.4265 - accuracy: 0.3427\n",
      "Epoch 6/20\n",
      " 95/100 [===========================>..] - ETA: 0s - loss: 1.3055 - accuracy: 0.3887\n",
      "Epoch 00006: loss improved from 1.42650 to 1.31493, saving model to model_DoctorChat.h5\n",
      "100/100 [==============================] - 9s 93ms/sample - loss: 1.3149 - accuracy: 0.3843\n",
      "Epoch 7/20\n",
      " 95/100 [===========================>..] - ETA: 0s - loss: 1.2227 - accuracy: 0.4120\n",
      "Epoch 00007: loss improved from 1.31493 to 1.21439, saving model to model_DoctorChat.h5\n",
      "100/100 [==============================] - 9s 95ms/sample - loss: 1.2144 - accuracy: 0.4214\n",
      "Epoch 8/20\n",
      " 95/100 [===========================>..] - ETA: 0s - loss: 1.1166 - accuracy: 0.4624\n",
      "Epoch 00008: loss improved from 1.21439 to 1.12382, saving model to model_DoctorChat.h5\n",
      "100/100 [==============================] - 9s 93ms/sample - loss: 1.1238 - accuracy: 0.4577\n",
      "Epoch 9/20\n",
      " 95/100 [===========================>..] - ETA: 0s - loss: 1.0575 - accuracy: 0.4847\n",
      "Epoch 00009: loss improved from 1.12382 to 1.03939, saving model to model_DoctorChat.h5\n",
      "100/100 [==============================] - 9s 94ms/sample - loss: 1.0394 - accuracy: 0.4875\n",
      "Epoch 10/20\n",
      " 95/100 [===========================>..] - ETA: 0s - loss: 0.9498 - accuracy: 0.5352\n",
      "Epoch 00010: loss improved from 1.03939 to 0.96265, saving model to model_DoctorChat.h5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100/100 [==============================] - 9s 92ms/sample - loss: 0.9627 - accuracy: 0.5334\n",
      "Epoch 11/20\n",
      " 95/100 [===========================>..] - ETA: 0s - loss: 0.8757 - accuracy: 0.5734\n",
      "Epoch 00011: loss improved from 0.96265 to 0.89133, saving model to model_DoctorChat.h5\n",
      "100/100 [==============================] - 10s 100ms/sample - loss: 0.8913 - accuracy: 0.5724\n",
      "Epoch 12/20\n",
      " 95/100 [===========================>..] - ETA: 0s - loss: 0.8242 - accuracy: 0.6044\n",
      "Epoch 00012: loss improved from 0.89133 to 0.81897, saving model to model_DoctorChat.h5\n",
      "100/100 [==============================] - 9s 95ms/sample - loss: 0.8190 - accuracy: 0.6003\n",
      "Epoch 13/20\n",
      " 95/100 [===========================>..] - ETA: 0s - loss: 0.7562 - accuracy: 0.6389\n",
      "Epoch 00013: loss improved from 0.81897 to 0.74987, saving model to model_DoctorChat.h5\n",
      "100/100 [==============================] - 10s 97ms/sample - loss: 0.7499 - accuracy: 0.6461\n",
      "Epoch 14/20\n",
      " 95/100 [===========================>..] - ETA: 0s - loss: 0.6804 - accuracy: 0.6820\n",
      "Epoch 00014: loss improved from 0.74987 to 0.68512, saving model to model_DoctorChat.h5\n",
      "100/100 [==============================] - 10s 98ms/sample - loss: 0.6851 - accuracy: 0.6818\n",
      "Epoch 15/20\n",
      " 95/100 [===========================>..] - ETA: 0s - loss: 0.6320 - accuracy: 0.7060\n",
      "Epoch 00015: loss improved from 0.68512 to 0.62559, saving model to model_DoctorChat.h5\n",
      "100/100 [==============================] - 10s 97ms/sample - loss: 0.6256 - accuracy: 0.7038\n",
      "Epoch 16/20\n",
      " 95/100 [===========================>..] - ETA: 0s - loss: 0.5650 - accuracy: 0.7274\n",
      "Epoch 00016: loss improved from 0.62559 to 0.57030, saving model to model_DoctorChat.h5\n",
      "100/100 [==============================] - 10s 96ms/sample - loss: 0.5703 - accuracy: 0.7297\n",
      "Epoch 17/20\n",
      " 95/100 [===========================>..] - ETA: 0s - loss: 0.5203 - accuracy: 0.7544\n",
      "Epoch 00017: loss improved from 0.57030 to 0.51772, saving model to model_DoctorChat.h5\n",
      "100/100 [==============================] - 10s 98ms/sample - loss: 0.5177 - accuracy: 0.7559\n",
      "Epoch 18/20\n",
      " 95/100 [===========================>..] - ETA: 0s - loss: 0.4557 - accuracy: 0.7792\n",
      "Epoch 00018: loss improved from 0.51772 to 0.46240, saving model to model_DoctorChat.h5\n",
      "100/100 [==============================] - 10s 99ms/sample - loss: 0.4624 - accuracy: 0.7792\n",
      "Epoch 19/20\n",
      " 95/100 [===========================>..] - ETA: 0s - loss: 0.4106 - accuracy: 0.8001\n",
      "Epoch 00019: loss improved from 0.46240 to 0.41631, saving model to model_DoctorChat.h5\n",
      "100/100 [==============================] - 10s 97ms/sample - loss: 0.4163 - accuracy: 0.7991\n",
      "Epoch 20/20\n",
      " 95/100 [===========================>..] - ETA: 0s - loss: 0.3712 - accuracy: 0.8279\n",
      "Epoch 00020: loss improved from 0.41631 to 0.37302, saving model to model_DoctorChat.h5\n",
      "100/100 [==============================] - 10s 98ms/sample - loss: 0.3730 - accuracy: 0.8260\n",
      "111/100 Sets Completed.\n",
      "Train on 100 samples\n",
      "Epoch 1/20\n",
      " 95/100 [===========================>..] - ETA: 0s - loss: 2.3255 - accuracy: 0.1191\n",
      "Epoch 00001: loss improved from inf to 2.32636, saving model to model_DoctorChat.h5\n",
      "100/100 [==============================] - 12s 120ms/sample - loss: 2.3264 - accuracy: 0.1201\n",
      "Epoch 2/20\n",
      " 95/100 [===========================>..] - ETA: 0s - loss: 2.0808 - accuracy: 0.1714\n",
      "Epoch 00002: loss improved from 2.32636 to 2.04872, saving model to model_DoctorChat.h5\n",
      "100/100 [==============================] - 9s 92ms/sample - loss: 2.0487 - accuracy: 0.1703\n",
      "Epoch 3/20\n",
      " 95/100 [===========================>..] - ETA: 0s - loss: 1.8578 - accuracy: 0.2152\n",
      "Epoch 00003: loss improved from 2.04872 to 1.86037, saving model to model_DoctorChat.h5\n",
      "100/100 [==============================] - 10s 98ms/sample - loss: 1.8604 - accuracy: 0.2170\n",
      "Epoch 4/20\n",
      " 95/100 [===========================>..] - ETA: 0s - loss: 1.7558 - accuracy: 0.2540\n",
      "Epoch 00004: loss improved from 1.86037 to 1.71227, saving model to model_DoctorChat.h5\n",
      "100/100 [==============================] - 10s 97ms/sample - loss: 1.7123 - accuracy: 0.2568\n",
      "Epoch 5/20\n",
      " 95/100 [===========================>..] - ETA: 0s - loss: 1.5685 - accuracy: 0.3034\n",
      "Epoch 00005: loss improved from 1.71227 to 1.57957, saving model to model_DoctorChat.h5\n",
      "100/100 [==============================] - 10s 97ms/sample - loss: 1.5796 - accuracy: 0.2999\n",
      "Epoch 6/20\n",
      " 95/100 [===========================>..] - ETA: 0s - loss: 1.4493 - accuracy: 0.3437\n",
      "Epoch 00006: loss improved from 1.57957 to 1.46537, saving model to model_DoctorChat.h5\n",
      "100/100 [==============================] - 10s 97ms/sample - loss: 1.4654 - accuracy: 0.3416\n",
      "Epoch 7/20\n",
      " 95/100 [===========================>..] - ETA: 0s - loss: 1.3378 - accuracy: 0.3713\n",
      "Epoch 00007: loss improved from 1.46537 to 1.35463, saving model to model_DoctorChat.h5\n",
      "100/100 [==============================] - 10s 99ms/sample - loss: 1.3546 - accuracy: 0.3718\n",
      "Epoch 8/20\n",
      " 95/100 [===========================>..] - ETA: 0s - loss: 1.2388 - accuracy: 0.4144\n",
      "Epoch 00008: loss improved from 1.35463 to 1.25815, saving model to model_DoctorChat.h5\n",
      "100/100 [==============================] - 10s 97ms/sample - loss: 1.2581 - accuracy: 0.4126\n",
      "Epoch 9/20\n",
      " 95/100 [===========================>..] - ETA: 0s - loss: 1.1457 - accuracy: 0.4530\n",
      "Epoch 00009: loss improved from 1.25815 to 1.16480, saving model to model_DoctorChat.h5\n",
      "100/100 [==============================] - 10s 99ms/sample - loss: 1.1648 - accuracy: 0.4466\n",
      "Epoch 10/20\n",
      " 95/100 [===========================>..] - ETA: 0s - loss: 1.0755 - accuracy: 0.4933\n",
      "Epoch 00010: loss improved from 1.16480 to 1.07598, saving model to model_DoctorChat.h5\n",
      "100/100 [==============================] - 10s 97ms/sample - loss: 1.0760 - accuracy: 0.4893\n",
      "Epoch 11/20\n",
      " 95/100 [===========================>..] - ETA: 0s - loss: 0.9987 - accuracy: 0.5225\n",
      "Epoch 00011: loss improved from 1.07598 to 0.99301, saving model to model_DoctorChat.h5\n",
      "100/100 [==============================] - 10s 98ms/sample - loss: 0.9930 - accuracy: 0.5207\n",
      "Epoch 12/20\n",
      " 95/100 [===========================>..] - ETA: 0s - loss: 0.9256 - accuracy: 0.5495\n",
      "Epoch 00012: loss improved from 0.99301 to 0.91569, saving model to model_DoctorChat.h5\n",
      "100/100 [==============================] - 10s 99ms/sample - loss: 0.9157 - accuracy: 0.5554\n",
      "Epoch 13/20\n",
      " 95/100 [===========================>..] - ETA: 0s - loss: 0.8317 - accuracy: 0.6005\n",
      "Epoch 00013: loss improved from 0.91569 to 0.83904, saving model to model_DoctorChat.h5\n",
      "100/100 [==============================] - 12s 117ms/sample - loss: 0.8390 - accuracy: 0.5959\n",
      "Epoch 14/20\n",
      " 95/100 [===========================>..] - ETA: 0s - loss: 0.7489 - accuracy: 0.6348\n",
      "Epoch 00014: loss improved from 0.83904 to 0.76618, saving model to model_DoctorChat.h5\n",
      "100/100 [==============================] - 10s 97ms/sample - loss: 0.7662 - accuracy: 0.6318\n",
      "Epoch 15/20\n",
      " 95/100 [===========================>..] - ETA: 0s - loss: 0.6860 - accuracy: 0.6698\n",
      "Epoch 00015: loss improved from 0.76618 to 0.69743, saving model to model_DoctorChat.h5\n",
      "100/100 [==============================] - 10s 97ms/sample - loss: 0.6974 - accuracy: 0.6642\n",
      "Epoch 16/20\n",
      " 95/100 [===========================>..] - ETA: 0s - loss: 0.6196 - accuracy: 0.6978\n",
      "Epoch 00016: loss improved from 0.69743 to 0.63271, saving model to model_DoctorChat.h5\n",
      "100/100 [==============================] - 10s 97ms/sample - loss: 0.6327 - accuracy: 0.6927\n",
      "Epoch 17/20\n",
      " 95/100 [===========================>..] - ETA: 0s - loss: 0.5759 - accuracy: 0.7276\n",
      "Epoch 00017: loss improved from 0.63271 to 0.57545, saving model to model_DoctorChat.h5\n",
      "100/100 [==============================] - 10s 95ms/sample - loss: 0.5754 - accuracy: 0.7273\n",
      "Epoch 18/20\n",
      " 95/100 [===========================>..] - ETA: 0s - loss: 0.5185 - accuracy: 0.7497\n",
      "Epoch 00018: loss improved from 0.57545 to 0.51862, saving model to model_DoctorChat.h5\n",
      "100/100 [==============================] - 10s 97ms/sample - loss: 0.5186 - accuracy: 0.7494\n",
      "Epoch 19/20\n",
      " 95/100 [===========================>..] - ETA: 0s - loss: 0.4612 - accuracy: 0.7793\n",
      "Epoch 00019: loss improved from 0.51862 to 0.46573, saving model to model_DoctorChat.h5\n",
      "100/100 [==============================] - 10s 96ms/sample - loss: 0.4657 - accuracy: 0.7785\n",
      "Epoch 20/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 95/100 [===========================>..] - ETA: 0s - loss: 0.4271 - accuracy: 0.8044\n",
      "Epoch 00020: loss improved from 0.46573 to 0.41785, saving model to model_DoctorChat.h5\n",
      "100/100 [==============================] - 10s 95ms/sample - loss: 0.4179 - accuracy: 0.8038\n",
      "112/100 Sets Completed.\n",
      "Train on 100 samples\n",
      "Epoch 1/20\n",
      " 95/100 [===========================>..] - ETA: 0s - loss: 2.2547 - accuracy: 0.1120\n",
      "Epoch 00001: loss improved from inf to 2.25203, saving model to model_DoctorChat.h5\n",
      "100/100 [==============================] - 13s 128ms/sample - loss: 2.2520 - accuracy: 0.1124\n",
      "Epoch 2/20\n",
      " 95/100 [===========================>..] - ETA: 0s - loss: 2.0017 - accuracy: 0.1649\n",
      "Epoch 00002: loss improved from 2.25203 to 1.98392, saving model to model_DoctorChat.h5\n",
      "100/100 [==============================] - 10s 97ms/sample - loss: 1.9839 - accuracy: 0.1644\n",
      "Epoch 3/20\n",
      " 95/100 [===========================>..] - ETA: 0s - loss: 1.7954 - accuracy: 0.2123\n",
      "Epoch 00003: loss improved from 1.98392 to 1.80233, saving model to model_DoctorChat.h5\n",
      "100/100 [==============================] - 10s 96ms/sample - loss: 1.8023 - accuracy: 0.2097\n",
      "Epoch 4/20\n",
      " 95/100 [===========================>..] - ETA: 0s - loss: 1.6830 - accuracy: 0.2496\n",
      "Epoch 00004: loss improved from 1.80233 to 1.66016, saving model to model_DoctorChat.h5\n",
      "100/100 [==============================] - 10s 97ms/sample - loss: 1.6602 - accuracy: 0.2513\n",
      "Epoch 5/20\n",
      " 95/100 [===========================>..] - ETA: 0s - loss: 1.5020 - accuracy: 0.2938\n",
      "Epoch 00005: loss improved from 1.66016 to 1.52946, saving model to model_DoctorChat.h5\n",
      "100/100 [==============================] - 10s 95ms/sample - loss: 1.5295 - accuracy: 0.2943\n",
      "Epoch 6/20\n",
      " 95/100 [===========================>..] - ETA: 0s - loss: 1.4361 - accuracy: 0.3378\n",
      "Epoch 00006: loss improved from 1.52946 to 1.41704, saving model to model_DoctorChat.h5\n",
      "100/100 [==============================] - 10s 95ms/sample - loss: 1.4170 - accuracy: 0.3362\n",
      "Epoch 7/20\n",
      " 95/100 [===========================>..] - ETA: 0s - loss: 1.2898 - accuracy: 0.3894\n",
      "Epoch 00007: loss improved from 1.41704 to 1.31119, saving model to model_DoctorChat.h5\n",
      "100/100 [==============================] - 10s 97ms/sample - loss: 1.3112 - accuracy: 0.3862\n",
      "Epoch 8/20\n",
      " 95/100 [===========================>..] - ETA: 0s - loss: 1.1679 - accuracy: 0.4291\n",
      "Epoch 00008: loss improved from 1.31119 to 1.21601, saving model to model_DoctorChat.h5\n",
      "100/100 [==============================] - 10s 96ms/sample - loss: 1.2160 - accuracy: 0.4275\n",
      "Epoch 9/20\n",
      " 95/100 [===========================>..] - ETA: 0s - loss: 1.0924 - accuracy: 0.4618\n",
      "Epoch 00009: loss improved from 1.21601 to 1.12926, saving model to model_DoctorChat.h5\n",
      "100/100 [==============================] - 10s 97ms/sample - loss: 1.1293 - accuracy: 0.4554\n",
      "Epoch 10/20\n",
      " 95/100 [===========================>..] - ETA: 0s - loss: 1.0386 - accuracy: 0.5023\n",
      "Epoch 00010: loss improved from 1.12926 to 1.04436, saving model to model_DoctorChat.h5\n",
      "100/100 [==============================] - 10s 97ms/sample - loss: 1.0444 - accuracy: 0.4990\n",
      "Epoch 11/20\n",
      " 95/100 [===========================>..] - ETA: 0s - loss: 0.9837 - accuracy: 0.5344\n",
      "Epoch 00011: loss improved from 1.04436 to 0.96778, saving model to model_DoctorChat.h5\n",
      "100/100 [==============================] - 10s 97ms/sample - loss: 0.9678 - accuracy: 0.5342\n",
      "Epoch 12/20\n",
      " 95/100 [===========================>..] - ETA: 0s - loss: 0.8935 - accuracy: 0.5814\n",
      "Epoch 00012: loss improved from 0.96778 to 0.88712, saving model to model_DoctorChat.h5\n",
      "100/100 [==============================] - 10s 97ms/sample - loss: 0.8871 - accuracy: 0.5832\n",
      "Epoch 13/20\n",
      " 95/100 [===========================>..] - ETA: 0s - loss: 0.8345 - accuracy: 0.6054\n",
      "Epoch 00013: loss improved from 0.88712 to 0.81858, saving model to model_DoctorChat.h5\n",
      "100/100 [==============================] - 9s 94ms/sample - loss: 0.8186 - accuracy: 0.6070\n",
      "Epoch 14/20\n",
      " 95/100 [===========================>..] - ETA: 0s - loss: 0.7583 - accuracy: 0.6466\n",
      "Epoch 00014: loss improved from 0.81858 to 0.74777, saving model to model_DoctorChat.h5\n",
      "100/100 [==============================] - 10s 96ms/sample - loss: 0.7478 - accuracy: 0.6463\n",
      "Epoch 15/20\n",
      " 95/100 [===========================>..] - ETA: 0s - loss: 0.6623 - accuracy: 0.6782\n",
      "Epoch 00015: loss improved from 0.74777 to 0.68180, saving model to model_DoctorChat.h5\n",
      "100/100 [==============================] - 10s 96ms/sample - loss: 0.6818 - accuracy: 0.6705\n",
      "Epoch 16/20\n",
      " 95/100 [===========================>..] - ETA: 0s - loss: 0.6274 - accuracy: 0.7001\n",
      "Epoch 00016: loss improved from 0.68180 to 0.62108, saving model to model_DoctorChat.h5\n",
      "100/100 [==============================] - 10s 96ms/sample - loss: 0.6211 - accuracy: 0.7003\n",
      "Epoch 17/20\n",
      " 95/100 [===========================>..] - ETA: 0s - loss: 0.5749 - accuracy: 0.7252\n",
      "Epoch 00017: loss improved from 0.62108 to 0.56235, saving model to model_DoctorChat.h5\n",
      "100/100 [==============================] - 10s 97ms/sample - loss: 0.5623 - accuracy: 0.7289\n",
      "Epoch 18/20\n",
      " 95/100 [===========================>..] - ETA: 0s - loss: 0.5022 - accuracy: 0.7593\n",
      "Epoch 00018: loss improved from 0.56235 to 0.50513, saving model to model_DoctorChat.h5\n",
      "100/100 [==============================] - 10s 96ms/sample - loss: 0.5051 - accuracy: 0.7564\n",
      "Epoch 19/20\n",
      " 95/100 [===========================>..] - ETA: 0s - loss: 0.4513 - accuracy: 0.7761\n",
      "Epoch 00019: loss improved from 0.50513 to 0.45094, saving model to model_DoctorChat.h5\n",
      "100/100 [==============================] - 10s 98ms/sample - loss: 0.4509 - accuracy: 0.7785\n",
      "Epoch 20/20\n",
      " 95/100 [===========================>..] - ETA: 0s - loss: 0.4047 - accuracy: 0.8050\n",
      "Epoch 00020: loss improved from 0.45094 to 0.40446, saving model to model_DoctorChat.h5\n",
      "100/100 [==============================] - 10s 96ms/sample - loss: 0.4045 - accuracy: 0.8057\n",
      "113/100 Sets Completed.\n",
      "Train on 100 samples\n",
      "Epoch 1/20\n",
      " 95/100 [===========================>..] - ETA: 0s - loss: 1.9534 - accuracy: 0.1471\n",
      "Epoch 00001: loss improved from inf to 2.00460, saving model to model_DoctorChat.h5\n",
      "100/100 [==============================] - 12s 124ms/sample - loss: 2.0046 - accuracy: 0.1469\n",
      "Epoch 2/20\n",
      " 95/100 [===========================>..] - ETA: 0s - loss: 1.7666 - accuracy: 0.1951\n",
      "Epoch 00002: loss improved from 2.00460 to 1.75841, saving model to model_DoctorChat.h5\n",
      "100/100 [==============================] - 10s 96ms/sample - loss: 1.7584 - accuracy: 0.1948\n",
      "Epoch 3/20\n",
      " 95/100 [===========================>..] - ETA: 0s - loss: 1.5825 - accuracy: 0.2500\n",
      "Epoch 00003: loss improved from 1.75841 to 1.59131, saving model to model_DoctorChat.h5\n",
      "100/100 [==============================] - 10s 97ms/sample - loss: 1.5913 - accuracy: 0.2473\n",
      "Epoch 4/20\n",
      " 95/100 [===========================>..] - ETA: 0s - loss: 1.4365 - accuracy: 0.2998\n",
      "Epoch 00004: loss improved from 1.59131 to 1.45814, saving model to model_DoctorChat.h5\n",
      "100/100 [==============================] - 11s 108ms/sample - loss: 1.4581 - accuracy: 0.2938\n",
      "Epoch 5/20\n",
      " 95/100 [===========================>..] - ETA: 0s - loss: 1.3422 - accuracy: 0.3327\n",
      "Epoch 00005: loss improved from 1.45814 to 1.33935, saving model to model_DoctorChat.h5\n",
      "100/100 [==============================] - 10s 101ms/sample - loss: 1.3393 - accuracy: 0.3381\n",
      "Epoch 6/20\n",
      " 95/100 [===========================>..] - ETA: 0s - loss: 1.2689 - accuracy: 0.3768\n",
      "Epoch 00006: loss improved from 1.33935 to 1.23983, saving model to model_DoctorChat.h5\n",
      "100/100 [==============================] - 10s 98ms/sample - loss: 1.2398 - accuracy: 0.3785\n",
      "Epoch 7/20\n",
      " 95/100 [===========================>..] - ETA: 0s - loss: 1.1737 - accuracy: 0.4175\n",
      "Epoch 00007: loss improved from 1.23983 to 1.14648, saving model to model_DoctorChat.h5\n",
      "100/100 [==============================] - 10s 100ms/sample - loss: 1.1465 - accuracy: 0.4164\n",
      "Epoch 8/20\n",
      " 95/100 [===========================>..] - ETA: 0s - loss: 1.0532 - accuracy: 0.4691\n",
      "Epoch 00008: loss improved from 1.14648 to 1.05832, saving model to model_DoctorChat.h5\n",
      "100/100 [==============================] - 10s 97ms/sample - loss: 1.0583 - accuracy: 0.4635\n",
      "Epoch 9/20\n",
      " 95/100 [===========================>..] - ETA: 0s - loss: 0.9755 - accuracy: 0.4931\n",
      "Epoch 00009: loss improved from 1.05832 to 0.97644, saving model to model_DoctorChat.h5\n",
      "100/100 [==============================] - 10s 98ms/sample - loss: 0.9764 - accuracy: 0.4925\n",
      "Epoch 10/20\n",
      " 95/100 [===========================>..] - ETA: 0s - loss: 0.9008 - accuracy: 0.5391\n",
      "Epoch 00010: loss improved from 0.97644 to 0.90321, saving model to model_DoctorChat.h5\n",
      "100/100 [==============================] - 10s 95ms/sample - loss: 0.9032 - accuracy: 0.5379\n",
      "Epoch 11/20\n",
      " 95/100 [===========================>..] - ETA: 0s - loss: 0.8534 - accuracy: 0.5723\n",
      "Epoch 00011: loss improved from 0.90321 to 0.83081, saving model to model_DoctorChat.h5\n",
      "100/100 [==============================] - 10s 97ms/sample - loss: 0.8308 - accuracy: 0.5747\n",
      "Epoch 12/20\n",
      " 95/100 [===========================>..] - ETA: 0s - loss: 0.7628 - accuracy: 0.6150\n",
      "Epoch 00012: loss improved from 0.83081 to 0.75969, saving model to model_DoctorChat.h5\n",
      "100/100 [==============================] - 10s 97ms/sample - loss: 0.7597 - accuracy: 0.6137\n",
      "Epoch 13/20\n",
      " 95/100 [===========================>..] - ETA: 0s - loss: 0.7212 - accuracy: 0.6371\n",
      "Epoch 00013: loss improved from 0.75969 to 0.70348, saving model to model_DoctorChat.h5\n",
      "100/100 [==============================] - 10s 97ms/sample - loss: 0.7035 - accuracy: 0.6408\n",
      "Epoch 14/20\n",
      " 95/100 [===========================>..] - ETA: 0s - loss: 0.6353 - accuracy: 0.6729\n",
      "Epoch 00014: loss improved from 0.70348 to 0.63980, saving model to model_DoctorChat.h5\n",
      "100/100 [==============================] - 10s 98ms/sample - loss: 0.6398 - accuracy: 0.6694\n",
      "Epoch 15/20\n",
      " 95/100 [===========================>..] - ETA: 0s - loss: 0.5875 - accuracy: 0.7104\n",
      "Epoch 00015: loss improved from 0.63980 to 0.58296, saving model to model_DoctorChat.h5\n",
      "100/100 [==============================] - 10s 98ms/sample - loss: 0.5830 - accuracy: 0.7094\n",
      "Epoch 16/20\n",
      " 95/100 [===========================>..] - ETA: 0s - loss: 0.5259 - accuracy: 0.7386\n",
      "Epoch 00016: loss improved from 0.58296 to 0.52771, saving model to model_DoctorChat.h5\n",
      "100/100 [==============================] - 10s 97ms/sample - loss: 0.5277 - accuracy: 0.7398\n",
      "Epoch 17/20\n",
      " 95/100 [===========================>..] - ETA: 0s - loss: 0.4826 - accuracy: 0.7579\n",
      "Epoch 00017: loss improved from 0.52771 to 0.47529, saving model to model_DoctorChat.h5\n",
      "100/100 [==============================] - 10s 99ms/sample - loss: 0.4753 - accuracy: 0.7573\n",
      "Epoch 18/20\n",
      " 95/100 [===========================>..] - ETA: 0s - loss: 0.4208 - accuracy: 0.7833\n",
      "Epoch 00018: loss improved from 0.47529 to 0.42748, saving model to model_DoctorChat.h5\n",
      "100/100 [==============================] - 10s 98ms/sample - loss: 0.4275 - accuracy: 0.7791\n",
      "Epoch 19/20\n",
      " 95/100 [===========================>..] - ETA: 0s - loss: 0.3781 - accuracy: 0.8022\n",
      "Epoch 00019: loss improved from 0.42748 to 0.38358, saving model to model_DoctorChat.h5\n",
      "100/100 [==============================] - 10s 98ms/sample - loss: 0.3836 - accuracy: 0.8016\n",
      "Epoch 20/20\n",
      " 95/100 [===========================>..] - ETA: 0s - loss: 0.3381 - accuracy: 0.8273\n",
      "Epoch 00020: loss improved from 0.38358 to 0.33986, saving model to model_DoctorChat.h5\n",
      "100/100 [==============================] - 10s 95ms/sample - loss: 0.3399 - accuracy: 0.8281\n",
      "114/100 Sets Completed.\n",
      "Train on 100 samples\n",
      "Epoch 1/20\n",
      " 95/100 [===========================>..] - ETA: 0s - loss: 2.1368 - accuracy: 0.1415\n",
      "Epoch 00001: loss improved from inf to 2.12764, saving model to model_DoctorChat.h5\n",
      "100/100 [==============================] - 13s 134ms/sample - loss: 2.1276 - accuracy: 0.1399\n",
      "Epoch 2/20\n",
      " 95/100 [===========================>..] - ETA: 0s - loss: 1.8944 - accuracy: 0.1917\n",
      "Epoch 00002: loss improved from 2.12764 to 1.87171, saving model to model_DoctorChat.h5\n",
      "100/100 [==============================] - 10s 97ms/sample - loss: 1.8717 - accuracy: 0.1922\n",
      "Epoch 3/20\n",
      " 95/100 [===========================>..] - ETA: 0s - loss: 1.7232 - accuracy: 0.2353\n",
      "Epoch 00003: loss improved from 1.87171 to 1.69475, saving model to model_DoctorChat.h5\n",
      "100/100 [==============================] - 10s 99ms/sample - loss: 1.6948 - accuracy: 0.2399\n",
      "Epoch 4/20\n",
      " 95/100 [===========================>..] - ETA: 0s - loss: 1.5629 - accuracy: 0.2735\n",
      "Epoch 00004: loss improved from 1.69475 to 1.55338, saving model to model_DoctorChat.h5\n",
      "100/100 [==============================] - 10s 97ms/sample - loss: 1.5534 - accuracy: 0.2736\n",
      "Epoch 5/20\n",
      " 95/100 [===========================>..] - ETA: 0s - loss: 1.4530 - accuracy: 0.3085\n",
      "Epoch 00005: loss improved from 1.55338 to 1.43108, saving model to model_DoctorChat.h5\n",
      "100/100 [==============================] - 10s 95ms/sample - loss: 1.4311 - accuracy: 0.3125\n",
      "Epoch 6/20\n",
      " 95/100 [===========================>..] - ETA: 0s - loss: 1.3479 - accuracy: 0.3504\n",
      "Epoch 00006: loss improved from 1.43108 to 1.32585, saving model to model_DoctorChat.h5\n",
      "100/100 [==============================] - 10s 98ms/sample - loss: 1.3258 - accuracy: 0.3517\n",
      "Epoch 7/20\n",
      " 95/100 [===========================>..] - ETA: 0s - loss: 1.2342 - accuracy: 0.3921\n",
      "Epoch 00007: loss improved from 1.32585 to 1.22463, saving model to model_DoctorChat.h5\n",
      "100/100 [==============================] - 10s 97ms/sample - loss: 1.2246 - accuracy: 0.3922\n",
      "Epoch 8/20\n",
      " 95/100 [===========================>..] - ETA: 0s - loss: 1.1369 - accuracy: 0.4329\n",
      "Epoch 00008: loss improved from 1.22463 to 1.13215, saving model to model_DoctorChat.h5\n",
      "100/100 [==============================] - 10s 98ms/sample - loss: 1.1321 - accuracy: 0.4345\n",
      "Epoch 9/20\n",
      " 95/100 [===========================>..] - ETA: 0s - loss: 1.0681 - accuracy: 0.4589\n",
      "Epoch 00009: loss improved from 1.13215 to 1.04978, saving model to model_DoctorChat.h5\n",
      "100/100 [==============================] - 10s 101ms/sample - loss: 1.0498 - accuracy: 0.4624\n",
      "Epoch 10/20\n",
      " 95/100 [===========================>..] - ETA: 0s - loss: 0.9702 - accuracy: 0.5103\n",
      "Epoch 00010: loss improved from 1.04978 to 0.96910, saving model to model_DoctorChat.h5\n",
      "100/100 [==============================] - 10s 99ms/sample - loss: 0.9691 - accuracy: 0.5074\n",
      "Epoch 11/20\n",
      " 95/100 [===========================>..] - ETA: 0s - loss: 0.8982 - accuracy: 0.5450\n",
      "Epoch 00011: loss improved from 0.96910 to 0.89253, saving model to model_DoctorChat.h5\n",
      "100/100 [==============================] - 10s 99ms/sample - loss: 0.8925 - accuracy: 0.5480\n",
      "Epoch 12/20\n",
      " 95/100 [===========================>..] - ETA: 0s - loss: 0.8023 - accuracy: 0.5758\n",
      "Epoch 00012: loss improved from 0.89253 to 0.82753, saving model to model_DoctorChat.h5\n",
      "100/100 [==============================] - 10s 98ms/sample - loss: 0.8275 - accuracy: 0.5686\n",
      "Epoch 13/20\n",
      " 95/100 [===========================>..] - ETA: 0s - loss: 0.7625 - accuracy: 0.6003\n",
      "Epoch 00013: loss improved from 0.82753 to 0.76118, saving model to model_DoctorChat.h5\n",
      "100/100 [==============================] - 10s 99ms/sample - loss: 0.7612 - accuracy: 0.6043\n",
      "Epoch 14/20\n",
      " 95/100 [===========================>..] - ETA: 0s - loss: 0.6962 - accuracy: 0.6532\n",
      "Epoch 00014: loss improved from 0.76118 to 0.69744, saving model to model_DoctorChat.h5\n",
      "100/100 [==============================] - 10s 97ms/sample - loss: 0.6974 - accuracy: 0.6514\n",
      "Epoch 15/20\n",
      " 95/100 [===========================>..] - ETA: 0s - loss: 0.6426 - accuracy: 0.6784\n",
      "Epoch 00015: loss improved from 0.69744 to 0.63720, saving model to model_DoctorChat.h5\n",
      "100/100 [==============================] - 10s 98ms/sample - loss: 0.6372 - accuracy: 0.6765\n",
      "Epoch 16/20\n",
      " 95/100 [===========================>..] - ETA: 0s - loss: 0.5828 - accuracy: 0.7007\n",
      "Epoch 00016: loss improved from 0.63720 to 0.58113, saving model to model_DoctorChat.h5\n",
      "100/100 [==============================] - 10s 97ms/sample - loss: 0.5811 - accuracy: 0.7020\n",
      "Epoch 17/20\n",
      " 95/100 [===========================>..] - ETA: 0s - loss: 0.5277 - accuracy: 0.7305\n",
      "Epoch 00017: loss improved from 0.58113 to 0.52580, saving model to model_DoctorChat.h5\n",
      "100/100 [==============================] - 10s 98ms/sample - loss: 0.5258 - accuracy: 0.7305\n",
      "Epoch 18/20\n",
      " 95/100 [===========================>..] - ETA: 0s - loss: 0.4479 - accuracy: 0.7746\n",
      "Epoch 00018: loss improved from 0.52580 to 0.47647, saving model to model_DoctorChat.h5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100/100 [==============================] - 10s 96ms/sample - loss: 0.4765 - accuracy: 0.7601\n",
      "Epoch 19/20\n",
      " 95/100 [===========================>..] - ETA: 0s - loss: 0.4381 - accuracy: 0.7800\n",
      "Epoch 00019: loss improved from 0.47647 to 0.42891, saving model to model_DoctorChat.h5\n",
      "100/100 [==============================] - 10s 98ms/sample - loss: 0.4289 - accuracy: 0.7796\n",
      "Epoch 20/20\n",
      " 95/100 [===========================>..] - ETA: 0s - loss: 0.3636 - accuracy: 0.8133\n",
      "Epoch 00020: loss improved from 0.42891 to 0.38385, saving model to model_DoctorChat.h5\n",
      "100/100 [==============================] - 10s 103ms/sample - loss: 0.3839 - accuracy: 0.8034\n",
      "115/100 Sets Completed.\n",
      "Train on 100 samples\n",
      "Epoch 1/20\n",
      " 95/100 [===========================>..] - ETA: 0s - loss: 2.1610 - accuracy: 0.1220\n",
      "Epoch 00001: loss improved from inf to 2.21226, saving model to model_DoctorChat.h5\n",
      "100/100 [==============================] - 12s 124ms/sample - loss: 2.2123 - accuracy: 0.1202\n",
      "Epoch 2/20\n",
      " 95/100 [===========================>..] - ETA: 0s - loss: 1.9498 - accuracy: 0.1735\n",
      "Epoch 00002: loss improved from 2.21226 to 1.95068, saving model to model_DoctorChat.h5\n",
      "100/100 [==============================] - 10s 98ms/sample - loss: 1.9507 - accuracy: 0.1700\n",
      "Epoch 3/20\n",
      " 95/100 [===========================>..] - ETA: 0s - loss: 1.7703 - accuracy: 0.2066\n",
      "Epoch 00003: loss improved from 1.95068 to 1.77257, saving model to model_DoctorChat.h5\n",
      "100/100 [==============================] - 10s 97ms/sample - loss: 1.7726 - accuracy: 0.2074\n",
      "Epoch 4/20\n",
      " 95/100 [===========================>..] - ETA: 0s - loss: 1.5998 - accuracy: 0.2483\n",
      "Epoch 00004: loss improved from 1.77257 to 1.62768, saving model to model_DoctorChat.h5\n",
      "100/100 [==============================] - 10s 97ms/sample - loss: 1.6277 - accuracy: 0.2448\n",
      "Epoch 5/20\n",
      " 95/100 [===========================>..] - ETA: 0s - loss: 1.4775 - accuracy: 0.2868\n",
      "Epoch 00005: loss improved from 1.62768 to 1.49488, saving model to model_DoctorChat.h5\n",
      "100/100 [==============================] - 10s 97ms/sample - loss: 1.4949 - accuracy: 0.2846\n",
      "Epoch 6/20\n",
      " 95/100 [===========================>..] - ETA: 0s - loss: 1.4053 - accuracy: 0.3288\n",
      "Epoch 00006: loss improved from 1.49488 to 1.38266, saving model to model_DoctorChat.h5\n",
      "100/100 [==============================] - 10s 99ms/sample - loss: 1.3827 - accuracy: 0.3279\n",
      "Epoch 7/20\n",
      " 95/100 [===========================>..] - ETA: 0s - loss: 1.3038 - accuracy: 0.3603\n",
      "Epoch 00007: loss improved from 1.38266 to 1.27953, saving model to model_DoctorChat.h5\n",
      "100/100 [==============================] - 10s 99ms/sample - loss: 1.2795 - accuracy: 0.3615\n",
      "Epoch 8/20\n",
      " 95/100 [===========================>..] - ETA: 0s - loss: 1.1934 - accuracy: 0.3981\n",
      "Epoch 00008: loss improved from 1.27953 to 1.18404, saving model to model_DoctorChat.h5\n",
      "100/100 [==============================] - 11s 108ms/sample - loss: 1.1840 - accuracy: 0.3961\n",
      "Epoch 9/20\n",
      " 95/100 [===========================>..] - ETA: 0s - loss: 1.1115 - accuracy: 0.4278\n",
      "Epoch 00009: loss improved from 1.18404 to 1.09793, saving model to model_DoctorChat.h5\n",
      "100/100 [==============================] - 10s 97ms/sample - loss: 1.0979 - accuracy: 0.4297\n",
      "Epoch 10/20\n",
      " 95/100 [===========================>..] - ETA: 0s - loss: 1.0186 - accuracy: 0.4815\n",
      "Epoch 00010: loss improved from 1.09793 to 1.00997, saving model to model_DoctorChat.h5\n",
      "100/100 [==============================] - 10s 98ms/sample - loss: 1.0100 - accuracy: 0.4799\n",
      "Epoch 11/20\n",
      " 95/100 [===========================>..] - ETA: 0s - loss: 0.9214 - accuracy: 0.5066\n",
      "Epoch 00011: loss improved from 1.00997 to 0.93518, saving model to model_DoctorChat.h5\n",
      "100/100 [==============================] - 10s 101ms/sample - loss: 0.9352 - accuracy: 0.5059\n",
      "Epoch 12/20\n",
      " 95/100 [===========================>..] - ETA: 0s - loss: 0.8654 - accuracy: 0.5534\n",
      "Epoch 00012: loss improved from 0.93518 to 0.86047, saving model to model_DoctorChat.h5\n",
      "100/100 [==============================] - 10s 95ms/sample - loss: 0.8605 - accuracy: 0.5544\n",
      "Epoch 13/20\n",
      " 95/100 [===========================>..] - ETA: 0s - loss: 0.7983 - accuracy: 0.5826\n",
      "Epoch 00013: loss improved from 0.86047 to 0.79056, saving model to model_DoctorChat.h5\n",
      "100/100 [==============================] - 10s 100ms/sample - loss: 0.7906 - accuracy: 0.5821\n",
      "Epoch 14/20\n",
      " 95/100 [===========================>..] - ETA: 0s - loss: 0.7329 - accuracy: 0.6300\n",
      "Epoch 00014: loss improved from 0.79056 to 0.72366, saving model to model_DoctorChat.h5\n",
      "100/100 [==============================] - 10s 99ms/sample - loss: 0.7237 - accuracy: 0.6309\n",
      "Epoch 15/20\n",
      " 95/100 [===========================>..] - ETA: 0s - loss: 0.6628 - accuracy: 0.6642\n",
      "Epoch 00015: loss improved from 0.72366 to 0.65982, saving model to model_DoctorChat.h5\n",
      "100/100 [==============================] - 10s 96ms/sample - loss: 0.6598 - accuracy: 0.6638\n",
      "Epoch 16/20\n",
      " 95/100 [===========================>..] - ETA: 0s - loss: 0.6048 - accuracy: 0.6920\n",
      "Epoch 00016: loss improved from 0.65982 to 0.60125, saving model to model_DoctorChat.h5\n",
      "100/100 [==============================] - 10s 98ms/sample - loss: 0.6012 - accuracy: 0.6929\n",
      "Epoch 17/20\n",
      " 95/100 [===========================>..] - ETA: 0s - loss: 0.5419 - accuracy: 0.7280\n",
      "Epoch 00017: loss improved from 0.60125 to 0.54375, saving model to model_DoctorChat.h5\n",
      "100/100 [==============================] - 10s 97ms/sample - loss: 0.5437 - accuracy: 0.7268\n",
      "Epoch 18/20\n",
      " 95/100 [===========================>..] - ETA: 0s - loss: 0.4986 - accuracy: 0.7495\n",
      "Epoch 00018: loss improved from 0.54375 to 0.49401, saving model to model_DoctorChat.h5\n",
      "100/100 [==============================] - 10s 97ms/sample - loss: 0.4940 - accuracy: 0.7524\n",
      "Epoch 19/20\n",
      " 95/100 [===========================>..] - ETA: 0s - loss: 0.4511 - accuracy: 0.7753\n",
      "Epoch 00019: loss improved from 0.49401 to 0.44167, saving model to model_DoctorChat.h5\n",
      "100/100 [==============================] - 10s 97ms/sample - loss: 0.4417 - accuracy: 0.7770\n",
      "Epoch 20/20\n",
      " 95/100 [===========================>..] - ETA: 0s - loss: 0.3928 - accuracy: 0.8043\n",
      "Epoch 00020: loss improved from 0.44167 to 0.39608, saving model to model_DoctorChat.h5\n",
      "100/100 [==============================] - 10s 102ms/sample - loss: 0.3961 - accuracy: 0.8037\n",
      "116/100 Sets Completed.\n",
      "Train on 100 samples\n",
      "Epoch 1/20\n",
      " 95/100 [===========================>..] - ETA: 0s - loss: 2.3641 - accuracy: 0.1341\n",
      "Epoch 00001: loss improved from inf to 2.38649, saving model to model_DoctorChat.h5\n",
      "100/100 [==============================] - 13s 133ms/sample - loss: 2.3865 - accuracy: 0.1320\n",
      "Epoch 2/20\n",
      " 95/100 [===========================>..] - ETA: 0s - loss: 2.1369 - accuracy: 0.1719\n",
      "Epoch 00002: loss improved from 2.38649 to 2.11623, saving model to model_DoctorChat.h5\n",
      "100/100 [==============================] - 10s 97ms/sample - loss: 2.1162 - accuracy: 0.1732\n",
      "Epoch 3/20\n",
      " 95/100 [===========================>..] - ETA: 0s - loss: 1.9072 - accuracy: 0.2096\n",
      "Epoch 00003: loss improved from 2.11623 to 1.93153, saving model to model_DoctorChat.h5\n",
      "100/100 [==============================] - 10s 98ms/sample - loss: 1.9315 - accuracy: 0.2099\n",
      "Epoch 4/20\n",
      " 95/100 [===========================>..] - ETA: 0s - loss: 1.7667 - accuracy: 0.2456\n",
      "Epoch 00004: loss improved from 1.93153 to 1.77934, saving model to model_DoctorChat.h5\n",
      "100/100 [==============================] - 10s 101ms/sample - loss: 1.7793 - accuracy: 0.2454\n",
      "Epoch 5/20\n",
      " 95/100 [===========================>..] - ETA: 0s - loss: 1.6785 - accuracy: 0.2789\n",
      "Epoch 00005: loss improved from 1.77934 to 1.64727, saving model to model_DoctorChat.h5\n",
      "100/100 [==============================] - 10s 97ms/sample - loss: 1.6473 - accuracy: 0.2794\n",
      "Epoch 6/20\n",
      " 95/100 [===========================>..] - ETA: 0s - loss: 1.5320 - accuracy: 0.3239\n",
      "Epoch 00006: loss improved from 1.64727 to 1.52061, saving model to model_DoctorChat.h5\n",
      "100/100 [==============================] - 10s 95ms/sample - loss: 1.5206 - accuracy: 0.3250\n",
      "Epoch 7/20\n",
      " 95/100 [===========================>..] - ETA: 0s - loss: 1.4424 - accuracy: 0.3632\n",
      "Epoch 00007: loss improved from 1.52061 to 1.41537, saving model to model_DoctorChat.h5\n",
      "100/100 [==============================] - 10s 97ms/sample - loss: 1.4154 - accuracy: 0.3639\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/20\n",
      " 95/100 [===========================>..] - ETA: 0s - loss: 1.3174 - accuracy: 0.4015\n",
      "Epoch 00008: loss improved from 1.41537 to 1.31204, saving model to model_DoctorChat.h5\n",
      "100/100 [==============================] - 10s 98ms/sample - loss: 1.3120 - accuracy: 0.4010\n",
      "Epoch 9/20\n",
      " 95/100 [===========================>..] - ETA: 0s - loss: 1.2166 - accuracy: 0.4432\n",
      "Epoch 00009: loss improved from 1.31204 to 1.21913, saving model to model_DoctorChat.h5\n",
      "100/100 [==============================] - 10s 98ms/sample - loss: 1.2191 - accuracy: 0.4415\n",
      "Epoch 10/20\n",
      " 95/100 [===========================>..] - ETA: 0s - loss: 1.1457 - accuracy: 0.4810\n",
      "Epoch 00010: loss improved from 1.21913 to 1.12960, saving model to model_DoctorChat.h5\n",
      "100/100 [==============================] - 10s 97ms/sample - loss: 1.1296 - accuracy: 0.4840\n",
      "Epoch 11/20\n",
      " 95/100 [===========================>..] - ETA: 0s - loss: 1.0519 - accuracy: 0.5138\n",
      "Epoch 00011: loss improved from 1.12960 to 1.04329, saving model to model_DoctorChat.h5\n",
      "100/100 [==============================] - 10s 98ms/sample - loss: 1.0433 - accuracy: 0.5160\n",
      "Epoch 12/20\n",
      " 95/100 [===========================>..] - ETA: 0s - loss: 0.9573 - accuracy: 0.5528\n",
      "Epoch 00012: loss improved from 1.04329 to 0.96693, saving model to model_DoctorChat.h5\n",
      "100/100 [==============================] - 10s 97ms/sample - loss: 0.9669 - accuracy: 0.5556\n",
      "Epoch 13/20\n",
      " 95/100 [===========================>..] - ETA: 0s - loss: 0.8933 - accuracy: 0.5877\n",
      "Epoch 00013: loss improved from 0.96693 to 0.88519, saving model to model_DoctorChat.h5\n",
      "100/100 [==============================] - 10s 97ms/sample - loss: 0.8852 - accuracy: 0.5899\n",
      "Epoch 14/20\n",
      " 95/100 [===========================>..] - ETA: 0s - loss: 0.8107 - accuracy: 0.6304\n",
      "Epoch 00014: loss improved from 0.88519 to 0.81625, saving model to model_DoctorChat.h5\n",
      "100/100 [==============================] - 10s 96ms/sample - loss: 0.8163 - accuracy: 0.6273\n",
      "Epoch 15/20\n",
      " 95/100 [===========================>..] - ETA: 0s - loss: 0.7426 - accuracy: 0.6593\n",
      "Epoch 00015: loss improved from 0.81625 to 0.74787, saving model to model_DoctorChat.h5\n",
      "100/100 [==============================] - 10s 97ms/sample - loss: 0.7479 - accuracy: 0.6596\n",
      "Epoch 16/20\n",
      " 95/100 [===========================>..] - ETA: 0s - loss: 0.6947 - accuracy: 0.6888\n",
      "Epoch 00016: loss improved from 0.74787 to 0.68107, saving model to model_DoctorChat.h5\n",
      "100/100 [==============================] - 10s 98ms/sample - loss: 0.6811 - accuracy: 0.6901\n",
      "Epoch 17/20\n",
      " 95/100 [===========================>..] - ETA: 0s - loss: 0.6251 - accuracy: 0.7194\n",
      "Epoch 00017: loss improved from 0.68107 to 0.61671, saving model to model_DoctorChat.h5\n",
      "100/100 [==============================] - 10s 100ms/sample - loss: 0.6167 - accuracy: 0.7234\n",
      "Epoch 18/20\n",
      " 95/100 [===========================>..] - ETA: 0s - loss: 0.5669 - accuracy: 0.7462\n",
      "Epoch 00018: loss improved from 0.61671 to 0.55832, saving model to model_DoctorChat.h5\n",
      "100/100 [==============================] - 10s 96ms/sample - loss: 0.5583 - accuracy: 0.7451\n",
      "Epoch 19/20\n",
      " 95/100 [===========================>..] - ETA: 0s - loss: 0.5091 - accuracy: 0.7666\n",
      "Epoch 00019: loss improved from 0.55832 to 0.50715, saving model to model_DoctorChat.h5\n",
      "100/100 [==============================] - 10s 98ms/sample - loss: 0.5072 - accuracy: 0.7668\n",
      "Epoch 20/20\n",
      " 95/100 [===========================>..] - ETA: 0s - loss: 0.4611 - accuracy: 0.7960\n",
      "Epoch 00020: loss improved from 0.50715 to 0.45642, saving model to model_DoctorChat.h5\n",
      "100/100 [==============================] - 10s 96ms/sample - loss: 0.4564 - accuracy: 0.7973\n",
      "117/100 Sets Completed.\n",
      "Train on 100 samples\n",
      "Epoch 1/20\n",
      " 95/100 [===========================>..] - ETA: 0s - loss: 2.4999 - accuracy: 0.1265\n",
      "Epoch 00001: loss improved from inf to 2.49218, saving model to model_DoctorChat.h5\n",
      "100/100 [==============================] - 13s 132ms/sample - loss: 2.4922 - accuracy: 0.1277\n",
      "Epoch 2/20\n",
      " 95/100 [===========================>..] - ETA: 0s - loss: 2.2660 - accuracy: 0.1698\n",
      "Epoch 00002: loss improved from 2.49218 to 2.20718, saving model to model_DoctorChat.h5\n",
      "100/100 [==============================] - 10s 98ms/sample - loss: 2.2072 - accuracy: 0.1713\n",
      "Epoch 3/20\n",
      " 95/100 [===========================>..] - ETA: 0s - loss: 2.0268 - accuracy: 0.2196\n",
      "Epoch 00003: loss improved from 2.20718 to 2.01093, saving model to model_DoctorChat.h5\n",
      "100/100 [==============================] - 10s 101ms/sample - loss: 2.0109 - accuracy: 0.2206\n",
      "Epoch 4/20\n",
      " 95/100 [===========================>..] - ETA: 0s - loss: 1.8405 - accuracy: 0.2557\n",
      "Epoch 00004: loss improved from 2.01093 to 1.84958, saving model to model_DoctorChat.h5\n",
      "100/100 [==============================] - 10s 99ms/sample - loss: 1.8496 - accuracy: 0.2547\n",
      "Epoch 5/20\n",
      " 95/100 [===========================>..] - ETA: 0s - loss: 1.7106 - accuracy: 0.2954\n",
      "Epoch 00005: loss improved from 1.84958 to 1.71439, saving model to model_DoctorChat.h5\n",
      "100/100 [==============================] - 10s 98ms/sample - loss: 1.7144 - accuracy: 0.2951\n",
      "Epoch 6/20\n",
      " 95/100 [===========================>..] - ETA: 0s - loss: 1.5760 - accuracy: 0.3361\n",
      "Epoch 00006: loss improved from 1.71439 to 1.58856, saving model to model_DoctorChat.h5\n",
      "100/100 [==============================] - 10s 98ms/sample - loss: 1.5886 - accuracy: 0.3336\n",
      "Epoch 7/20\n",
      " 95/100 [===========================>..] - ETA: 0s - loss: 1.4478 - accuracy: 0.3659\n",
      "Epoch 00007: loss improved from 1.58856 to 1.47263, saving model to model_DoctorChat.h5\n",
      "100/100 [==============================] - 10s 98ms/sample - loss: 1.4726 - accuracy: 0.3635\n",
      "Epoch 8/20\n",
      " 95/100 [===========================>..] - ETA: 0s - loss: 1.3555 - accuracy: 0.4001\n",
      "Epoch 00008: loss improved from 1.47263 to 1.37152, saving model to model_DoctorChat.h5\n",
      "100/100 [==============================] - 10s 101ms/sample - loss: 1.3715 - accuracy: 0.4003\n",
      "Epoch 9/20\n",
      " 95/100 [===========================>..] - ETA: 0s - loss: 1.2819 - accuracy: 0.4528\n",
      "Epoch 00009: loss improved from 1.37152 to 1.27065, saving model to model_DoctorChat.h5\n",
      "100/100 [==============================] - 10s 98ms/sample - loss: 1.2707 - accuracy: 0.4499\n",
      "Epoch 10/20\n",
      " 95/100 [===========================>..] - ETA: 0s - loss: 1.2022 - accuracy: 0.4773\n",
      "Epoch 00010: loss improved from 1.27065 to 1.18238, saving model to model_DoctorChat.h5\n",
      "100/100 [==============================] - 10s 96ms/sample - loss: 1.1824 - accuracy: 0.4774\n",
      "Epoch 11/20\n",
      " 95/100 [===========================>..] - ETA: 0s - loss: 1.1026 - accuracy: 0.5173\n",
      "Epoch 00011: loss improved from 1.18238 to 1.09140, saving model to model_DoctorChat.h5\n",
      "100/100 [==============================] - 10s 96ms/sample - loss: 1.0914 - accuracy: 0.5190\n",
      "Epoch 12/20\n",
      " 95/100 [===========================>..] - ETA: 0s - loss: 0.9893 - accuracy: 0.5626\n",
      "Epoch 00012: loss improved from 1.09140 to 1.00731, saving model to model_DoctorChat.h5\n",
      "100/100 [==============================] - 10s 97ms/sample - loss: 1.0073 - accuracy: 0.5575\n",
      "Epoch 13/20\n",
      " 95/100 [===========================>..] - ETA: 0s - loss: 0.9361 - accuracy: 0.5859\n",
      "Epoch 00013: loss improved from 1.00731 to 0.93230, saving model to model_DoctorChat.h5\n",
      "100/100 [==============================] - 10s 96ms/sample - loss: 0.9323 - accuracy: 0.5877\n",
      "Epoch 14/20\n",
      " 95/100 [===========================>..] - ETA: 0s - loss: 0.8517 - accuracy: 0.6255\n",
      "Epoch 00014: loss improved from 0.93230 to 0.85241, saving model to model_DoctorChat.h5\n",
      "100/100 [==============================] - 10s 98ms/sample - loss: 0.8524 - accuracy: 0.6245\n",
      "Epoch 15/20\n",
      " 95/100 [===========================>..] - ETA: 0s - loss: 0.7847 - accuracy: 0.6544\n",
      "Epoch 00015: loss improved from 0.85241 to 0.78283, saving model to model_DoctorChat.h5\n",
      "100/100 [==============================] - 9s 95ms/sample - loss: 0.7828 - accuracy: 0.6550\n",
      "Epoch 16/20\n",
      " 95/100 [===========================>..] - ETA: 0s - loss: 0.7215 - accuracy: 0.6830\n",
      "Epoch 00016: loss improved from 0.78283 to 0.71604, saving model to model_DoctorChat.h5\n",
      "100/100 [==============================] - 10s 99ms/sample - loss: 0.7160 - accuracy: 0.6813\n",
      "Epoch 17/20\n",
      " 95/100 [===========================>..] - ETA: 0s - loss: 0.6609 - accuracy: 0.7104\n",
      "Epoch 00017: loss improved from 0.71604 to 0.65004, saving model to model_DoctorChat.h5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100/100 [==============================] - 10s 97ms/sample - loss: 0.6500 - accuracy: 0.7112\n",
      "Epoch 18/20\n",
      " 95/100 [===========================>..] - ETA: 0s - loss: 0.5767 - accuracy: 0.7417\n",
      "Epoch 00018: loss improved from 0.65004 to 0.58860, saving model to model_DoctorChat.h5\n",
      "100/100 [==============================] - 10s 96ms/sample - loss: 0.5886 - accuracy: 0.7372\n",
      "Epoch 19/20\n",
      " 95/100 [===========================>..] - ETA: 0s - loss: 0.5292 - accuracy: 0.7705\n",
      "Epoch 00019: loss improved from 0.58860 to 0.53283, saving model to model_DoctorChat.h5\n",
      "100/100 [==============================] - 10s 102ms/sample - loss: 0.5328 - accuracy: 0.7674\n",
      "Epoch 20/20\n",
      " 95/100 [===========================>..] - ETA: 0s - loss: 0.4827 - accuracy: 0.7947\n",
      "Epoch 00020: loss improved from 0.53283 to 0.47906, saving model to model_DoctorChat.h5\n",
      "100/100 [==============================] - 10s 101ms/sample - loss: 0.4791 - accuracy: 0.7940\n",
      "118/100 Sets Completed.\n",
      "Train on 100 samples\n",
      "Epoch 1/20\n",
      " 95/100 [===========================>..] - ETA: 0s - loss: 1.8827 - accuracy: 0.1327\n",
      "Epoch 00001: loss improved from inf to 1.87658, saving model to model_DoctorChat.h5\n",
      "100/100 [==============================] - 13s 132ms/sample - loss: 1.8766 - accuracy: 0.1332\n",
      "Epoch 2/20\n",
      " 95/100 [===========================>..] - ETA: 0s - loss: 1.6706 - accuracy: 0.1834\n",
      "Epoch 00002: loss improved from 1.87658 to 1.65269, saving model to model_DoctorChat.h5\n",
      "100/100 [==============================] - 10s 103ms/sample - loss: 1.6527 - accuracy: 0.1835\n",
      "Epoch 3/20\n",
      " 95/100 [===========================>..] - ETA: 0s - loss: 1.5063 - accuracy: 0.2380\n",
      "Epoch 00003: loss improved from 1.65269 to 1.49503, saving model to model_DoctorChat.h5\n",
      "100/100 [==============================] - 10s 97ms/sample - loss: 1.4950 - accuracy: 0.2385\n",
      "Epoch 4/20\n",
      " 95/100 [===========================>..] - ETA: 0s - loss: 1.3883 - accuracy: 0.2745\n",
      "Epoch 00004: loss improved from 1.49503 to 1.37064, saving model to model_DoctorChat.h5\n",
      "100/100 [==============================] - 10s 97ms/sample - loss: 1.3706 - accuracy: 0.2758\n",
      "Epoch 5/20\n",
      " 95/100 [===========================>..] - ETA: 0s - loss: 1.2465 - accuracy: 0.3232\n",
      "Epoch 00005: loss improved from 1.37064 to 1.26188, saving model to model_DoctorChat.h5\n",
      "100/100 [==============================] - 10s 97ms/sample - loss: 1.2619 - accuracy: 0.3250\n",
      "Epoch 6/20\n",
      " 95/100 [===========================>..] - ETA: 0s - loss: 1.1563 - accuracy: 0.3688\n",
      "Epoch 00006: loss improved from 1.26188 to 1.16085, saving model to model_DoctorChat.h5\n",
      "100/100 [==============================] - 10s 95ms/sample - loss: 1.1608 - accuracy: 0.3705\n",
      "Epoch 7/20\n",
      " 95/100 [===========================>..] - ETA: 0s - loss: 1.0454 - accuracy: 0.4127\n",
      "Epoch 00007: loss improved from 1.16085 to 1.07240, saving model to model_DoctorChat.h5\n",
      "100/100 [==============================] - 10s 96ms/sample - loss: 1.0724 - accuracy: 0.4063\n",
      "Epoch 8/20\n",
      " 95/100 [===========================>..] - ETA: 0s - loss: 0.9684 - accuracy: 0.4627\n",
      "Epoch 00008: loss improved from 1.07240 to 0.98973, saving model to model_DoctorChat.h5\n",
      "100/100 [==============================] - 10s 96ms/sample - loss: 0.9897 - accuracy: 0.4558\n",
      "Epoch 9/20\n",
      " 95/100 [===========================>..] - ETA: 0s - loss: 0.9056 - accuracy: 0.4965\n",
      "Epoch 00009: loss improved from 0.98973 to 0.91475, saving model to model_DoctorChat.h5\n",
      "100/100 [==============================] - 10s 99ms/sample - loss: 0.9147 - accuracy: 0.4908\n",
      "Epoch 10/20\n",
      " 95/100 [===========================>..] - ETA: 0s - loss: 0.8537 - accuracy: 0.5388\n",
      "Epoch 00010: loss improved from 0.91475 to 0.84125, saving model to model_DoctorChat.h5\n",
      "100/100 [==============================] - 9s 95ms/sample - loss: 0.8413 - accuracy: 0.5391\n",
      "Epoch 11/20\n",
      " 95/100 [===========================>..] - ETA: 0s - loss: 0.7824 - accuracy: 0.5652\n",
      "Epoch 00011: loss improved from 0.84125 to 0.77281, saving model to model_DoctorChat.h5\n",
      "100/100 [==============================] - 10s 96ms/sample - loss: 0.7728 - accuracy: 0.5697\n",
      "Epoch 12/20\n",
      " 95/100 [===========================>..] - ETA: 0s - loss: 0.6971 - accuracy: 0.6077\n",
      "Epoch 00012: loss improved from 0.77281 to 0.71065, saving model to model_DoctorChat.h5\n",
      "100/100 [==============================] - 10s 96ms/sample - loss: 0.7107 - accuracy: 0.6055\n",
      "Epoch 13/20\n",
      " 95/100 [===========================>..] - ETA: 0s - loss: 0.6469 - accuracy: 0.6393\n",
      "Epoch 00013: loss improved from 0.71065 to 0.64884, saving model to model_DoctorChat.h5\n",
      "100/100 [==============================] - 10s 97ms/sample - loss: 0.6488 - accuracy: 0.6381\n",
      "Epoch 14/20\n",
      " 95/100 [===========================>..] - ETA: 0s - loss: 0.5945 - accuracy: 0.6729\n",
      "Epoch 00014: loss improved from 0.64884 to 0.59430, saving model to model_DoctorChat.h5\n",
      "100/100 [==============================] - 10s 98ms/sample - loss: 0.5943 - accuracy: 0.6711\n",
      "Epoch 15/20\n",
      " 95/100 [===========================>..] - ETA: 0s - loss: 0.5478 - accuracy: 0.7011\n",
      "Epoch 00015: loss improved from 0.59430 to 0.53931, saving model to model_DoctorChat.h5\n",
      "100/100 [==============================] - 10s 98ms/sample - loss: 0.5393 - accuracy: 0.6998\n",
      "Epoch 16/20\n",
      " 95/100 [===========================>..] - ETA: 0s - loss: 0.4783 - accuracy: 0.7366\n",
      "Epoch 00016: loss improved from 0.53931 to 0.48610, saving model to model_DoctorChat.h5\n",
      "100/100 [==============================] - 10s 96ms/sample - loss: 0.4861 - accuracy: 0.7305\n",
      "Epoch 17/20\n",
      " 95/100 [===========================>..] - ETA: 0s - loss: 0.4392 - accuracy: 0.7515\n",
      "Epoch 00017: loss improved from 0.48610 to 0.44005, saving model to model_DoctorChat.h5\n",
      "100/100 [==============================] - 10s 98ms/sample - loss: 0.4401 - accuracy: 0.7517\n",
      "Epoch 18/20\n",
      " 95/100 [===========================>..] - ETA: 0s - loss: 0.3970 - accuracy: 0.7713\n",
      "Epoch 00018: loss improved from 0.44005 to 0.39430, saving model to model_DoctorChat.h5\n",
      "100/100 [==============================] - 10s 96ms/sample - loss: 0.3943 - accuracy: 0.7749\n",
      "Epoch 19/20\n",
      " 95/100 [===========================>..] - ETA: 0s - loss: 0.3518 - accuracy: 0.7846\n",
      "Epoch 00019: loss improved from 0.39430 to 0.35334, saving model to model_DoctorChat.h5\n",
      "100/100 [==============================] - 10s 99ms/sample - loss: 0.3533 - accuracy: 0.7862\n",
      "Epoch 20/20\n",
      " 95/100 [===========================>..] - ETA: 0s - loss: 0.3108 - accuracy: 0.8156\n",
      "Epoch 00020: loss improved from 0.35334 to 0.31514, saving model to model_DoctorChat.h5\n",
      "100/100 [==============================] - 10s 95ms/sample - loss: 0.3151 - accuracy: 0.8149\n",
      "119/100 Sets Completed.\n"
     ]
    }
   ],
   "source": [
    "# load the model\n",
    "for i in range(110,120):\n",
    "    Pre_D=prepare_data(final_QA[i][0],final_QA[i][1])\n",
    "    encoder_input_data=Pre_D[0]\n",
    "    decoder_input_data=Pre_D[1]\n",
    "    decoder_output_data=Pre_D[2]\n",
    "    maxlen_questions=Pre_D[3]\n",
    "    maxlen_answers=Pre_D[4]\n",
    "    model = models.load_model(filepath)\n",
    "    checkpoint = ModelCheckpoint(filepath, monitor='loss', verbose=1, save_best_only=True, mode='min')\n",
    "    callbacks_list = [checkpoint]\n",
    "    model.fit([encoder_input_data , decoder_input_data], decoder_output_data, epochs=20, batch_size=5, callbacks=callbacks_list)\n",
    "    #assert_allclose(model.predict(x_train),new_model.predict(x_train), 1e-5)\n",
    "    print(str(i)+'/100 Sets Completed.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save( r'model_DocChat1.h5' ) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Loaded_model = load_model( r'model_DocChat1.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(Loaded_model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_inference_models():\n",
    "    \n",
    "    encoder_model = tf.keras.models.Model(encoder_inputs, encoder_states)\n",
    "    \n",
    "    decoder_state_input_h = tf.keras.layers.Input(shape=( 200 ,))\n",
    "    decoder_state_input_c = tf.keras.layers.Input(shape=( 200 ,))\n",
    "    \n",
    "    decoder_states_inputs = [decoder_state_input_h, decoder_state_input_c]\n",
    "    \n",
    "    decoder_outputs, state_h, state_c = decoder_lstm(\n",
    "        decoder_embedding , initial_state=decoder_states_inputs)\n",
    "    decoder_states = [state_h, state_c]\n",
    "    decoder_outputs = decoder_dense(decoder_outputs)\n",
    "    decoder_model = tf.keras.models.Model(\n",
    "        [decoder_inputs] + decoder_states_inputs,\n",
    "        [decoder_outputs] + decoder_states)\n",
    "    \n",
    "    return encoder_model , decoder_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def str_to_tokens( sentence : str ):\n",
    "    words = sentence.lower().split()\n",
    "    tokens_list = list()\n",
    "    for word in words:\n",
    "        tokens_list.append( tokenizer.word_index[ word ] ) \n",
    "    return preprocessing.sequence.pad_sequences( [tokens_list] , maxlen=maxlen , padding='post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "enc_model , dec_model = make_inference_models()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Real time testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for _ in range(10):\n",
    "    try:\n",
    "        states_values = enc_model.predict( str_to_tokens( input( 'Enter question : ' ) ) )\n",
    "        empty_target_seq = np.zeros( ( 1 , 1 ) )\n",
    "        empty_target_seq[0, 0] = tokenizer.word_index['start']\n",
    "        stop_condition = False\n",
    "        decoded_translation = ''\n",
    "        while not stop_condition :\n",
    "            dec_outputs , h , c = dec_model.predict([ empty_target_seq ] + states_values )\n",
    "            sampled_word_index = np.argmax( dec_outputs[0, -1, :] )\n",
    "            sampled_word = None\n",
    "            for word , index in tokenizer.word_index.items() :\n",
    "                if sampled_word_index == index :\n",
    "                    decoded_translation += ' {}'.format( word )\n",
    "                    sampled_word = word\n",
    "            \n",
    "            if sampled_word == 'end' or len(decoded_translation.split()) > maxlen_answers:\n",
    "                stop_condition = True\n",
    "                \n",
    "            empty_target_seq = np.zeros( ( 1 , 1 ) )  \n",
    "            empty_target_seq[ 0 , 0 ] = sampled_word_index\n",
    "            states_values = [ h , c ] \n",
    "\n",
    "        print( \" \".join(decoded_translation.strip().split(\" \")[:-1]) )\n",
    "    except:\n",
    "        print(\"Sorry, I don't understand. Please try again.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7 GPU",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
